{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/lish-moa/test_features.csv\n/kaggle/input/lish-moa/train_features.csv\n/kaggle/input/lish-moa/train_targets_scored.csv\n/kaggle/input/lish-moa/train_targets_nonscored.csv\n/kaggle/input/lish-moa/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install iterative-stratification","execution_count":3,"outputs":[{"output_type":"stream","text":"Collecting iterative-stratification\n  Downloading iterative_stratification-0.1.6-py3-none-any.whl (8.7 kB)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from iterative-stratification) (0.23.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification) (1.4.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from iterative-stratification) (1.18.5)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification) (0.14.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->iterative-stratification) (2.1.0)\nInstalling collected packages: iterative-stratification\nSuccessfully installed iterative-stratification-0.1.6\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"        \nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.dataset import random_split\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n\n\nimport numpy as np \nimport pandas as pd \nfrom IPython.display import clear_output\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm, tnrange\n\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nplt.rcParams['figure.figsize'] = 15, 7\n\nCGREEN  = '\\33[32m'\nCBLUE =  '\\033[34m'\nCRED = '\\033[1;31m'\nCEND  = '\\33[0m'\n\ndef seed_everything(seed=42):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","execution_count":207,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if torch.cuda.is_available():\n    device='cuda'\nelse:\n    device='cpu'\n    \ndevice","execution_count":208,"outputs":[{"output_type":"execute_result","execution_count":208,"data":{"text/plain":"'cuda'"},"metadata":{}}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\ntrain_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\n","execution_count":303,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df):\n    df = df.copy()\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    return df\n\ntrain = preprocess(train_features)\ntest = preprocess(test_features)\n\ndel train_targets['sig_id']\n\ntarget = train_targets.loc[train['cp_type']==0].reset_index(drop=True)\ntrain = train.loc[train['cp_type']==0].reset_index(drop=True)","execution_count":304,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_features = [  1,   2,   3,   4,   5,   6,   7,   9,  11,  14,  15,  16,  17,\n        18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n        32,  33,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  46,\n        47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,  60,\n        61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n        74,  75,  76,  78,  79,  80,  81,  82,  83,  84,  86,  87,  88,\n        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n       115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n       129, 130, 131, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143,\n       144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197,\n       198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212,\n       213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226,\n       227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n       240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n       254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n       267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n       281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294,\n       295, 296, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n       310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n       324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n       337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n       350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n       363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 375, 376, 377,\n       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391,\n       392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404,\n       405, 406, 407, 408, 409, 411, 412, 413, 414, 415, 416, 417, 418,\n       419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n       432, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446,\n       447, 448, 449, 450, 453, 454, 456, 457, 458, 459, 460, 461, 462,\n       463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n       476, 477, 478, 479, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n       490, 491, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 505,\n       506, 507, 509, 510, 511, 512, 513, 514, 515, 518, 519, 520, 521,\n       522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 534, 535, 536,\n       538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 550, 551,\n       552, 554, 557, 559, 560, 561, 562, 565, 566, 567, 568, 569, 570,\n       571, 572, 573, 574, 575, 577, 578, 580, 581, 582, 583, 584, 585,\n       586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 599,\n       600, 601, 602, 606, 607, 608, 609, 611, 612, 613, 615, 616, 617,\n       618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630,\n       631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642, 643, 644,\n       645, 646, 647, 648, 649, 650, 651, 652, 654, 655, 656, 658, 659,\n       660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672,\n       673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n       686, 687, 688, 689, 691, 692, 693, 694, 695, 696, 697, 699, 700,\n       701, 702, 704, 705, 707, 708, 709, 710, 711, 713, 714, 716, 717,\n       718, 720, 721, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732,\n       733, 734, 735, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747,\n       748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 759, 760, 761,\n       762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774,\n       775, 776, 777, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788,\n       789, 790, 792, 793, 794, 795, 796, 797, 798, 800, 801, 802, 803,\n       804, 805, 806, 808, 809, 811, 813, 814, 815, 816, 817, 818, 819,\n       821, 822, 823, 825, 826, 827, 828, 829, 830, 831, 832, 834, 835,\n       837, 838, 839, 840, 841, 842, 845, 846, 847, 848, 850, 851, 852,\n       854, 855, 856, 858, 859, 860, 861, 862, 864, 866, 867, 868, 869,\n       870, 871, 872, 873, 874]","execution_count":305,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_columns = train.columns\ntrain=train[all_columns[top_features]]\ntest = test[all_columns[top_features]]","execution_count":306,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.values\ntest = test.values\ntarget = target.values\n","execution_count":307,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape, target.shape","execution_count":308,"outputs":[{"output_type":"execute_result","execution_count":308,"data":{"text/plain":"((21948, 785), (3982, 785), (21948, 206))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, train,targets, noise ):\n        \n        self.features  = train\n        self.targets = targets\n        self.noise = noise\n        \n    def sizes(self):\n        print(\"features size = \", self.features.shape[1])\n        print(\"targets size = \", self.targets.shape[1])\n\n        \n    def __len__(self):\n        return self.features.shape[0]\n\n    def __getitem__(self, idx):\n        feature = torch.tensor(self.features[idx]).float()\n        \n#         if self.noise == True:\n# #             print(\"noisy boi\")\n#             feature  = feature + torch.randn_like(feature)/150\n            \n        target = torch.tensor(self.targets[idx]).float()\n        \n        return feature, target","execution_count":309,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n        \ndef show_lr(learning_rates):\n    plt.plot(learning_rates, label = \"learning rate\")\n    plt.ylabel(\"Learning rate\", fontsize = 15)\n    plt.grid(True)\n    plt.legend()\n    plt.show()\n\ndef train_step(x, y, model, optimizer, criterion):\n    optimizer.zero_grad()\n    pred = model(x.to(device))\n    y = y.float()\n    loss = criterion(pred,y.to(device))\n    loss.backward()\n    optimizer.step()\n    return loss.item()","execution_count":216,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train test split for testing "},{"metadata":{"trusted":true},"cell_type":"code","source":"def validate_fn(model, val_loader, criterion, device):\n    model.eval()\n    losses = []\n    with torch.no_grad():\n        for batch in val_loader:\n            x, y = batch \n            pred = model(x.to(device))\n            loss = criterion(pred.cpu(),y).item()\n            losses.append(loss)\n    return np.array(losses).mean()\n\ndef create_weights_from_val_losses(val_losses_np):\n    w = 1/val_losses_np\n    w_norm = w/w.max()\n    return w_norm\n\n\ndef train_one_fold(model,num_epochs , train_loader,val_loader, optimizer, scheduler, criterion, fold_number = 1, show_plots = False, train = True, validate = True):\n    \n    losses = []\n    val_losses = []\n    learning_rates = []    \n    best_loss = 1000000\n\n    for epoch in range(num_epochs):\n\n            \n        if train == True:\n            model.train()\n            losses_temp = []\n            for batch in train_loader:\n                (x_batch, y_batch) = batch\n                loss = train_step(x_batch.to(device), y_batch.to(device), model, optimizer, criterion)\n                losses_temp.append(loss)\n            losses.append(torch.mean(torch.tensor(losses_temp)))\n            \n            if scheduler is not None:\n                scheduler.step(1.)   ## lr decay caller \n\n            learning_rates.append(get_lr(optimizer))\n            \n\n        if validate == True:\n            val_losses.append(validate_fn(model, val_loader, criterion, device))\n            \n\n        \n        if train == True:\n            print (\"epoch \", epoch+1, \" out of \", num_epochs, end = \"      >\" )\n\n            if val_losses[-1] <= best_loss:\n\n                print(CGREEN, \"Val loss decreased from:\", best_loss, \" to \", val_losses[-1], CEND, end = \"   >\")\n                best_loss = val_losses[-1]\n                name = \"./model_\" + str(fold_number)+\".pth\"\n                print(\"saving model as: \", name)\n                torch.save(model.state_dict(), name)\n\n            else: \n                print(\"showing no improvements, best loss yet:\", best_loss)\n\n        if show_plots == True:\n\n            show_lr(learning_rates)\n            plt.plot(val_losses, label = \"val\")\n            plt.axhline(min(val_losses), linestyle = \"--\", c = \"r\")\n            plt.legend()\n            plt.grid()\n            plt.show()\n\n\n            plt.plot(val_losses[4:], label = \"val after main drop\", c = \"g\")\n            plt.axhline(min(val_losses), linestyle = \"--\", c = \"r\")\n            plt.legend()\n            plt.grid()\n            plt.show()\n\n\n            plt.plot(losses, label = \"train\")\n            plt.legend()\n            plt.grid()\n            plt.show()\n        \n    if train == True:\n        return min(val_losses), name\n    else:\n        return min(val_losses)","execution_count":217,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfull_dataset = TrainDataset(train, target, noise = False)\n\ntrain_size = int(0.9* len(full_dataset))  ## 80/20 split\ntest_size = len(full_dataset) - train_size\ntrain_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n\nval_loader = DataLoader(dataset=test_dataset, batch_size= 512, shuffle = False)\n\nprint(len(train_loader), \"batches \")\nprint(len(val_loader), \" batches \")","execution_count":373,"outputs":[{"output_type":"stream","text":"155 batches \n5  batches \n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Model 1 "},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.batch_norm1 = nn.BatchNorm1d(785)\n        self.dropout1 = nn.Dropout(0.2)\n        self.dense1 = nn.utils.weight_norm(nn.Linear(785, 2048))\n        \n        self.batch_norm2 = nn.BatchNorm1d(2048)\n        self.dropout2 = nn.Dropout(0.5)\n        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1048))\n        \n        self.batch_norm3 = nn.BatchNorm1d(1048)\n        self.dropout3 = nn.Dropout(0.5)\n        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, 206))\n    \n    def forward(self, x):\n        x = self.batch_norm1(x)\n        x = self.dropout1(x)\n        x = F.relu(self.dense1(x))\n        \n        x = self.batch_norm2(x)\n        x = self.dropout2(x)\n        x = F.relu(self.dense2(x))\n        \n        x = self.batch_norm3(x)\n        x = self.dropout3(x)\n        x = self.dense3(x)\n        \n        return x","execution_count":374,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_filenames = []\nval_losses = []","execution_count":375,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 1 training "},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 45 ## changes here \n\nmodel = Model()\nmodel = model.to(device)\noptimizer = optim.Adam(model.parameters(), lr = 0.004299882049752947, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                 mode='min', \n                                                 factor=0.1, ## wooo hoo\n                                                 patience=7, ## was 3 for 158 \n                                                 eps=1e-4, \n                                                 verbose=True)\n\n\ncriterion = nn.BCEWithLogitsLoss()\n\nval_loss, filename = train_one_fold(model, num_epochs , train_loader,val_loader, optimizer, scheduler, criterion, fold_number = 1)\n\nval_losses.append(val_loss)\nmodel_filenames.append(filename)\n    \nprint(CBLUE, \"Training complete\", CEND)","execution_count":376,"outputs":[{"output_type":"stream","text":"epoch  1  out of  45      > Val loss decreased from: 1000000  to  0.021068791300058363    >saving model as:  ./model_1.pth\nepoch  2  out of  45      > Val loss decreased from: 0.021068791300058363  to  0.019239036738872527    >saving model as:  ./model_1.pth\nepoch  3  out of  45      > Val loss decreased from: 0.019239036738872527  to  0.018405894935131072    >saving model as:  ./model_1.pth\nepoch  4  out of  45      > Val loss decreased from: 0.018405894935131072  to  0.01796437203884125    >saving model as:  ./model_1.pth\nepoch  5  out of  45      > Val loss decreased from: 0.01796437203884125  to  0.017606330662965776    >saving model as:  ./model_1.pth\nepoch  6  out of  45      > Val loss decreased from: 0.017606330662965776  to  0.017410482466220855    >saving model as:  ./model_1.pth\nepoch  7  out of  45      > Val loss decreased from: 0.017410482466220855  to  0.017244889587163924    >saving model as:  ./model_1.pth\nepoch  8  out of  45      >showing no improvements, best loss yet: 0.017244889587163924\nEpoch     9: reducing learning rate of group 0 to 4.2999e-04.\nepoch  9  out of  45      >showing no improvements, best loss yet: 0.017244889587163924\nepoch  10  out of  45      > Val loss decreased from: 0.017244889587163924  to  0.016624150052666663    >saving model as:  ./model_1.pth\nepoch  11  out of  45      > Val loss decreased from: 0.016624150052666663  to  0.016497131437063217    >saving model as:  ./model_1.pth\nepoch  12  out of  45      > Val loss decreased from: 0.016497131437063217  to  0.016330499947071076    >saving model as:  ./model_1.pth\nepoch  13  out of  45      > Val loss decreased from: 0.016330499947071076  to  0.016284042596817018    >saving model as:  ./model_1.pth\nepoch  14  out of  45      > Val loss decreased from: 0.016284042596817018  to  0.016252396628260612    >saving model as:  ./model_1.pth\nepoch  15  out of  45      > Val loss decreased from: 0.016252396628260612  to  0.016191591694951057    >saving model as:  ./model_1.pth\nepoch  16  out of  45      > Val loss decreased from: 0.016191591694951057  to  0.016101856157183646    >saving model as:  ./model_1.pth\nEpoch    17: reducing learning rate of group 0 to 4.2999e-05.\nepoch  17  out of  45      >showing no improvements, best loss yet: 0.016101856157183646\nepoch  18  out of  45      > Val loss decreased from: 0.016101856157183646  to  0.016047199442982673    >saving model as:  ./model_1.pth\nepoch  19  out of  45      > Val loss decreased from: 0.016047199442982673  to  0.015999437496066093    >saving model as:  ./model_1.pth\nepoch  20  out of  45      > Val loss decreased from: 0.015999437496066093  to  0.015990399196743964    >saving model as:  ./model_1.pth\nepoch  21  out of  45      > Val loss decreased from: 0.015990399196743964  to  0.01597692407667637    >saving model as:  ./model_1.pth\nepoch  22  out of  45      > Val loss decreased from: 0.01597692407667637  to  0.015929216146469118    >saving model as:  ./model_1.pth\nepoch  23  out of  45      >showing no improvements, best loss yet: 0.015929216146469118\nepoch  24  out of  45      > Val loss decreased from: 0.015929216146469118  to  0.01592903807759285    >saving model as:  ./model_1.pth\nepoch  25  out of  45      > Val loss decreased from: 0.01592903807759285  to  0.015903185307979583    >saving model as:  ./model_1.pth\nepoch  26  out of  45      >showing no improvements, best loss yet: 0.015903185307979583\nepoch  27  out of  45      >showing no improvements, best loss yet: 0.015903185307979583\nepoch  28  out of  45      > Val loss decreased from: 0.015903185307979583  to  0.015893568471074104    >saving model as:  ./model_1.pth\nepoch  29  out of  45      >showing no improvements, best loss yet: 0.015893568471074104\nepoch  30  out of  45      >showing no improvements, best loss yet: 0.015893568471074104\nepoch  31  out of  45      >showing no improvements, best loss yet: 0.015893568471074104\nepoch  32  out of  45      >showing no improvements, best loss yet: 0.015893568471074104\nepoch  33  out of  45      > Val loss decreased from: 0.015893568471074104  to  0.015892477706074715    >saving model as:  ./model_1.pth\nepoch  34  out of  45      > Val loss decreased from: 0.015892477706074715  to  0.015877941995859145    >saving model as:  ./model_1.pth\nepoch  35  out of  45      >showing no improvements, best loss yet: 0.015877941995859145\nepoch  36  out of  45      > Val loss decreased from: 0.015877941995859145  to  0.01586463861167431    >saving model as:  ./model_1.pth\nepoch  37  out of  45      > Val loss decreased from: 0.01586463861167431  to  0.01584495771676302    >saving model as:  ./model_1.pth\nepoch  38  out of  45      > Val loss decreased from: 0.01584495771676302  to  0.015834295190870762    >saving model as:  ./model_1.pth\nepoch  39  out of  45      >showing no improvements, best loss yet: 0.015834295190870762\nepoch  40  out of  45      >showing no improvements, best loss yet: 0.015834295190870762\nepoch  41  out of  45      >showing no improvements, best loss yet: 0.015834295190870762\nepoch  42  out of  45      >showing no improvements, best loss yet: 0.015834295190870762\nepoch  43  out of  45      >showing no improvements, best loss yet: 0.015834295190870762\nepoch  44  out of  45      >showing no improvements, best loss yet: 0.015834295190870762\nepoch  45  out of  45      >showing no improvements, best loss yet: 0.015834295190870762\n Training complete \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_filenames","execution_count":377,"outputs":[{"output_type":"execute_result","execution_count":377,"data":{"text/plain":"['./model_1.pth']"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Model 2 "},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model_2(nn.Module):\n    def __init__(self):\n        super(Model_2, self).__init__()\n        self.batch_norm1 = nn.BatchNorm1d(785)\n        self.dropout1 = nn.Dropout(0.2)\n        self.dense1 = nn.utils.weight_norm(nn.Linear(785, 512))\n        \n        self.batch_norm4 = nn.BatchNorm1d(512)\n        self.dropout4 = nn.Dropout(0.5)\n        self.dense4 = nn.utils.weight_norm(nn.Linear(512, 206))\n    \n    \n    def forward(self, x):\n        x = self.batch_norm1(x)\n        x = self.dropout1(x)\n        x = F.leaky_relu(self.dense1(x))\n        \n        x = self.batch_norm4(x)\n        x = self.dropout4(x)\n        x = self.dense4(x)\n        \n        return x","execution_count":378,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 2 training"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 45 ## changes here \n\nmodel = Model_2()\nmodel = model.to(device)\noptimizer = optim.Adam(model.parameters(), lr = 4e-3, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                 mode='min', \n                                                 factor=0.1, ## wooo hoo\n                                                 patience=7, ## was 3 for 158 \n                                                 eps=1e-4, \n                                                 verbose=True)\n\n\ncriterion = nn.BCEWithLogitsLoss()\n\nval_loss, filename = train_one_fold(model, num_epochs , train_loader,val_loader, optimizer, scheduler, criterion, fold_number = 100)\n\n\nval_losses.append(val_loss)\nmodel_filenames.append(filename)\n    \n    \nprint(CBLUE, \"Training complete\", CEND)","execution_count":379,"outputs":[{"output_type":"stream","text":"epoch  1  out of  45      > Val loss decreased from: 1000000  to  0.021287448704242706    >saving model as:  ./model_100.pth\nepoch  2  out of  45      > Val loss decreased from: 0.021287448704242706  to  0.019070076942443847    >saving model as:  ./model_100.pth\nepoch  3  out of  45      > Val loss decreased from: 0.019070076942443847  to  0.01837366335093975    >saving model as:  ./model_100.pth\nepoch  4  out of  45      > Val loss decreased from: 0.01837366335093975  to  0.017764350026845933    >saving model as:  ./model_100.pth\nepoch  5  out of  45      > Val loss decreased from: 0.017764350026845933  to  0.017516466230154036    >saving model as:  ./model_100.pth\nepoch  6  out of  45      > Val loss decreased from: 0.017516466230154036  to  0.017311893031001092    >saving model as:  ./model_100.pth\nepoch  7  out of  45      > Val loss decreased from: 0.017311893031001092  to  0.01717060022056103    >saving model as:  ./model_100.pth\nepoch  8  out of  45      > Val loss decreased from: 0.01717060022056103  to  0.016960807889699937    >saving model as:  ./model_100.pth\nEpoch     9: reducing learning rate of group 0 to 4.0000e-04.\nepoch  9  out of  45      > Val loss decreased from: 0.016960807889699937  to  0.01693035438656807    >saving model as:  ./model_100.pth\nepoch  10  out of  45      > Val loss decreased from: 0.01693035438656807  to  0.01662486232817173    >saving model as:  ./model_100.pth\nepoch  11  out of  45      > Val loss decreased from: 0.01662486232817173  to  0.016508181020617484    >saving model as:  ./model_100.pth\nepoch  12  out of  45      > Val loss decreased from: 0.016508181020617484  to  0.016418084874749182    >saving model as:  ./model_100.pth\nepoch  13  out of  45      > Val loss decreased from: 0.016418084874749182  to  0.01639013849198818    >saving model as:  ./model_100.pth\nepoch  14  out of  45      > Val loss decreased from: 0.01639013849198818  to  0.016336778551340102    >saving model as:  ./model_100.pth\nepoch  15  out of  45      > Val loss decreased from: 0.016336778551340102  to  0.016333635523915292    >saving model as:  ./model_100.pth\nepoch  16  out of  45      > Val loss decreased from: 0.016333635523915292  to  0.016293033212423324    >saving model as:  ./model_100.pth\nEpoch    17: reducing learning rate of group 0 to 4.0000e-05.\nepoch  17  out of  45      >showing no improvements, best loss yet: 0.016293033212423324\nepoch  18  out of  45      > Val loss decreased from: 0.016293033212423324  to  0.016277604177594183    >saving model as:  ./model_100.pth\nepoch  19  out of  45      > Val loss decreased from: 0.016277604177594183  to  0.016248944029212    >saving model as:  ./model_100.pth\nepoch  20  out of  45      > Val loss decreased from: 0.016248944029212  to  0.016246651113033295    >saving model as:  ./model_100.pth\nepoch  21  out of  45      > Val loss decreased from: 0.016246651113033295  to  0.016214238852262496    >saving model as:  ./model_100.pth\nepoch  22  out of  45      >showing no improvements, best loss yet: 0.016214238852262496\nepoch  23  out of  45      >showing no improvements, best loss yet: 0.016214238852262496\nepoch  24  out of  45      >showing no improvements, best loss yet: 0.016214238852262496\nepoch  25  out of  45      > Val loss decreased from: 0.016214238852262496  to  0.01621212884783745    >saving model as:  ./model_100.pth\nepoch  26  out of  45      >showing no improvements, best loss yet: 0.01621212884783745\nepoch  27  out of  45      > Val loss decreased from: 0.01621212884783745  to  0.01620781868696213    >saving model as:  ./model_100.pth\nepoch  28  out of  45      > Val loss decreased from: 0.01620781868696213  to  0.016178402304649352    >saving model as:  ./model_100.pth\nepoch  29  out of  45      >showing no improvements, best loss yet: 0.016178402304649352\nepoch  30  out of  45      >showing no improvements, best loss yet: 0.016178402304649352\nepoch  31  out of  45      >showing no improvements, best loss yet: 0.016178402304649352\nepoch  32  out of  45      >showing no improvements, best loss yet: 0.016178402304649352\nepoch  33  out of  45      > Val loss decreased from: 0.016178402304649352  to  0.016170659288764    >saving model as:  ./model_100.pth\nepoch  34  out of  45      >showing no improvements, best loss yet: 0.016170659288764\nepoch  35  out of  45      >showing no improvements, best loss yet: 0.016170659288764\nepoch  36  out of  45      >showing no improvements, best loss yet: 0.016170659288764\nepoch  37  out of  45      > Val loss decreased from: 0.016170659288764  to  0.016160092130303384    >saving model as:  ./model_100.pth\nepoch  38  out of  45      >showing no improvements, best loss yet: 0.016160092130303384\nepoch  39  out of  45      >showing no improvements, best loss yet: 0.016160092130303384\nepoch  40  out of  45      >showing no improvements, best loss yet: 0.016160092130303384\nepoch  41  out of  45      > Val loss decreased from: 0.016160092130303384  to  0.01613880954682827    >saving model as:  ./model_100.pth\nepoch  42  out of  45      >showing no improvements, best loss yet: 0.01613880954682827\nepoch  43  out of  45      >showing no improvements, best loss yet: 0.01613880954682827\nepoch  44  out of  45      >showing no improvements, best loss yet: 0.01613880954682827\nepoch  45  out of  45      >showing no improvements, best loss yet: 0.01613880954682827\n Training complete \n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Model blending"},{"metadata":{"trusted":true},"cell_type":"code","source":"class blend(nn.Module):\n    def __init__(self,weights, model_list ,model_filenames, device = device):\n        super(blend, self).__init__()\n#         print(\"loading models...\")\n        self.model_filenames = model_filenames\n        self.model_list = model_list\n        self.weights = weights \n\n        for i in range(len(self.model_filenames)):\n            self.model_list[i].load_state_dict(torch.load(self.model_filenames[i]))\n            self.model_list[i].to(device)\n            self.model_list[i].eval()\n            \n#         print(\"done loading from\", self.model_filenames)\n\n    def forward(self, x):\n        \n        x_list = [self.model_list[i](x).detach().cpu() for i in range(len(self.model_list))]\n        \n        final_pred = torch.zeros_like(x_list[0])\n        for i in range(len(x_list)):\n            final_pred += x_list[i] * self.weights[i]\n            \n        final_pred = final_pred/self.weights.sum()\n        \n        return final_pred.cpu()","execution_count":380,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = create_weights_from_val_losses(np.array(val_losses))\nbb = blend(\n    weights = weights, \n    model_list = [Model(), Model_2()],\n    model_filenames = model_filenames\n)","execution_count":381,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_filenames","execution_count":382,"outputs":[{"output_type":"execute_result","execution_count":382,"data":{"text/plain":"['./model_1.pth', './model_100.pth']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_models = [Model(), Model_2()]\ntest_val_losses = {}\n\nfor i in range(len(model_filenames)):\n    all_models[i].load_state_dict(torch.load(model_filenames[i]))\n    all_models[i].to(device)\n    all_models[i].eval()\n    \nall_val_losses = []\n\nwith torch.no_grad():\n    for i in range(len(all_models)):\n        val_loss = validate_fn(all_models[i], val_loader, criterion, device)\n        test_val_losses[\"model_\" + str(i+1)] = val_loss\n    print(\"done validating\")\n\ntest_val_losses","execution_count":383,"outputs":[{"output_type":"stream","text":"done validating\n","name":"stdout"},{"output_type":"execute_result","execution_count":383,"data":{"text/plain":"{'model_1': 0.015834295190870762, 'model_2': 0.01613880954682827}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss = validate_fn(bb, val_loader, criterion, device)\ntest_val_losses[\"model_blend\"] = val_loss\n\n","execution_count":385,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'font.size': 15})\n\nnames = test_val_losses.keys()\nvals = test_val_losses.values()\n\nplt.bar(names, vals)\nplt.ylim(min(vals)- .0002, max(vals) + 0.0002)\nplt.ylabel(\"loss on validation set\", fontsize = 18)\nplt.xlabel(\"models ->\", fontsize = 15)\nplt.axhline(y = min(vals), linestyle = \"--\", c = \"r\", linewidth = 5)\nplt.show()","execution_count":386,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1080x504 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"# Finding good weights, better than the ones made from val losses "},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna","execution_count":387,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validate_trial( val_loader, criterion, device, params):\n    bb = blend(\n    weights = np.array([params[\"w1\"], params[\"w2\"]]), \n    model_list = [Model(), Model_2()],\n    model_filenames = model_filenames\n    )\n    \n    loss_ = validate_fn(bb,val_loader, criterion, device)\n    return loss_","execution_count":388,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial):\n    params = {\n        \"w1\": trial.suggest_uniform(\"w1\", 0.001, 1.0),\n        \"w2\": trial.suggest_uniform(\"w2\", 0.001, 1.0)\n    }\n    loss_ = validate_trial(val_loader,criterion, device, params)\n    return loss_\n","execution_count":389,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study(direction=\"minimize\")\n","execution_count":390,"outputs":[{"output_type":"stream","text":"[I 2020-10-01 05:27:45,813] A new study created in memory with name: no-name-ce727115-8dcc-41d3-b728-257245932fa1\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"study.optimize(objective, n_trials=400)\n\n","execution_count":391,"outputs":[{"output_type":"stream","text":"[I 2020-10-01 05:27:47,303] Trial 0 finished with value: 0.016004518419504166 and parameters: {'w1': 0.15051765946156137, 'w2': 0.5079892092830627}. Best is trial 0 with value: 0.016004518419504166.\n[I 2020-10-01 05:27:47,498] Trial 1 finished with value: 0.015901945903897284 and parameters: {'w1': 0.5328091143362652, 'w2': 0.5820717017698599}. Best is trial 1 with value: 0.015901945903897284.\n[I 2020-10-01 05:27:47,699] Trial 2 finished with value: 0.015894747525453567 and parameters: {'w1': 0.2738097823192691, 'w2': 0.2728192631834364}. Best is trial 2 with value: 0.015894747525453567.\n[I 2020-10-01 05:27:47,899] Trial 3 finished with value: 0.016108262166380883 and parameters: {'w1': 0.03893352424642978, 'w2': 0.7976909704814051}. Best is trial 2 with value: 0.015894747525453567.\n[I 2020-10-01 05:27:48,111] Trial 4 finished with value: 0.01583998966962099 and parameters: {'w1': 0.9769746314298314, 'w2': 0.3057957937636394}. Best is trial 4 with value: 0.01583998966962099.\n[I 2020-10-01 05:27:48,311] Trial 5 finished with value: 0.015915777906775473 and parameters: {'w1': 0.26895657529532274, 'w2': 0.34686365905025324}. Best is trial 4 with value: 0.01583998966962099.\n[I 2020-10-01 05:27:48,509] Trial 6 finished with value: 0.015993812307715415 and parameters: {'w1': 0.09751143027405072, 'w2': 0.2921656653482813}. Best is trial 4 with value: 0.01583998966962099.\n[I 2020-10-01 05:27:48,707] Trial 7 finished with value: 0.01596651002764702 and parameters: {'w1': 0.2260769501634295, 'w2': 0.5056190170698791}. Best is trial 4 with value: 0.01583998966962099.\n[I 2020-10-01 05:27:48,906] Trial 8 finished with value: 0.015831538662314414 and parameters: {'w1': 0.17959501233464945, 'w2': 0.022761717185869102}. Best is trial 8 with value: 0.015831538662314414.\n[I 2020-10-01 05:27:49,134] Trial 9 finished with value: 0.01588694639503956 and parameters: {'w1': 0.23093699103615806, 'w2': 0.2069854980970311}. Best is trial 8 with value: 0.015831538662314414.\n[I 2020-10-01 05:27:49,341] Trial 10 finished with value: 0.01583371665328741 and parameters: {'w1': 0.5353150429954697, 'w2': 0.10720806090331286}. Best is trial 8 with value: 0.015831538662314414.\n[I 2020-10-01 05:27:49,546] Trial 11 finished with value: 0.015833814814686775 and parameters: {'w1': 0.5668119903673989, 'w2': 0.004135179858934496}. Best is trial 8 with value: 0.015831538662314414.\n[I 2020-10-01 05:27:49,747] Trial 12 finished with value: 0.015833540260791777 and parameters: {'w1': 0.8129838932980612, 'w2': 0.009659373447165782}. Best is trial 8 with value: 0.015831538662314414.\n[I 2020-10-01 05:27:49,947] Trial 13 finished with value: 0.0158315472304821 and parameters: {'w1': 0.8261419355590907, 'w2': 0.054623704686874275}. Best is trial 8 with value: 0.015831538662314414.\n[I 2020-10-01 05:27:50,146] Trial 14 finished with value: 0.015906152501702308 and parameters: {'w1': 0.8490637843169996, 'w2': 0.9768899868896519}. Best is trial 8 with value: 0.015831538662314414.\n[I 2020-10-01 05:27:50,347] Trial 15 finished with value: 0.015831777639687062 and parameters: {'w1': 0.7032171750811154, 'w2': 0.09851967564423231}. Best is trial 8 with value: 0.015831538662314414.\n[I 2020-10-01 05:27:50,657] Trial 16 finished with value: 0.01584323085844517 and parameters: {'w1': 0.3765316464840415, 'w2': 0.13539681860367808}. Best is trial 8 with value: 0.015831538662314414.\n[I 2020-10-01 05:27:50,857] Trial 17 finished with value: 0.01589643508195877 and parameters: {'w1': 0.6785797688757098, 'w2': 0.6911762444812374}. Best is trial 8 with value: 0.015831538662314414.\n[I 2020-10-01 05:27:51,088] Trial 18 finished with value: 0.015833618864417077 and parameters: {'w1': 0.9847627833542832, 'w2': 0.010376669705879471}. Best is trial 8 with value: 0.015831538662314414.\n[I 2020-10-01 05:27:51,286] Trial 19 finished with value: 0.01589469388127327 and parameters: {'w1': 0.39332564009363247, 'w2': 0.3916201746553529}. Best is trial 8 with value: 0.015831538662314414.\n[I 2020-10-01 05:27:51,479] Trial 20 finished with value: 0.01584948059171438 and parameters: {'w1': 0.40958865725553567, 'w2': 0.18090017044640885}. Best is trial 8 with value: 0.015831538662314414.\n[I 2020-10-01 05:27:51,678] Trial 21 finished with value: 0.015831326507031916 and parameters: {'w1': 0.7153957392798985, 'w2': 0.07603499422588321}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:51,874] Trial 22 finished with value: 0.01583150550723076 and parameters: {'w1': 0.8523793918790543, 'w2': 0.05862124340806717}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:52,077] Trial 23 finished with value: 0.01583977472037077 and parameters: {'w1': 0.6709171028576371, 'w2': 0.2078027686473039}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:52,279] Trial 24 finished with value: 0.015833842381834985 and parameters: {'w1': 0.8975306327425301, 'w2': 0.006174600746147327}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:52,477] Trial 25 finished with value: 0.01583146583288908 and parameters: {'w1': 0.742493101830306, 'w2': 0.09033077148829745}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:52,676] Trial 26 finished with value: 0.01585916131734848 and parameters: {'w1': 0.77390509248655, 'w2': 0.43339558857943034}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:52,877] Trial 27 finished with value: 0.015832133032381533 and parameters: {'w1': 0.9161138603106037, 'w2': 0.14188297227340807}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:53,156] Trial 28 finished with value: 0.015842861123383047 and parameters: {'w1': 0.6240681527028361, 'w2': 0.22122630726107556}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:53,555] Trial 29 finished with value: 0.01583150364458561 and parameters: {'w1': 0.7126135115074729, 'w2': 0.08863059673925916}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:53,838] Trial 30 finished with value: 0.01591733768582344 and parameters: {'w1': 0.7491363754369551, 'w2': 0.9837005139686681}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:54,057] Trial 31 finished with value: 0.015831479243934153 and parameters: {'w1': 0.6105899465582459, 'w2': 0.0748680680703852}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:54,272] Trial 32 finished with value: 0.015831957384943963 and parameters: {'w1': 0.6113554617049536, 'w2': 0.09039835438098077}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:54,477] Trial 33 finished with value: 0.015840478613972662 and parameters: {'w1': 0.4955279322631238, 'w2': 0.15870466127439875}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:54,679] Trial 34 finished with value: 0.015855420753359793 and parameters: {'w1': 0.4873224322589631, 'w2': 0.25095340075094413}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:54,886] Trial 35 finished with value: 0.015881335735321044 and parameters: {'w1': 0.7377890884066489, 'w2': 0.6097557289957818}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:55,092] Trial 36 finished with value: 0.01583147943019867 and parameters: {'w1': 0.6235324022841757, 'w2': 0.07641297359443436}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:55,297] Trial 37 finished with value: 0.01585101503878832 and parameters: {'w1': 0.6186036806674128, 'w2': 0.2851060469251959}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:55,508] Trial 38 finished with value: 0.015873407758772374 and parameters: {'w1': 0.46808572129822723, 'w2': 0.3417568243690728}. Best is trial 21 with value: 0.015831326507031916.\n[I 2020-10-01 05:27:55,715] Trial 39 finished with value: 0.01583131290972233 and parameters: {'w1': 0.5950787848666097, 'w2': 0.05238291746109742}. Best is trial 39 with value: 0.01583131290972233.\n[I 2020-10-01 05:27:55,929] Trial 40 finished with value: 0.015839363262057305 and parameters: {'w1': 0.5651791688867307, 'w2': 0.17150325925998483}. Best is trial 39 with value: 0.01583131290972233.\n","name":"stderr"},{"output_type":"stream","text":"[I 2020-10-01 05:27:56,137] Trial 41 finished with value: 0.01583130843937397 and parameters: {'w1': 0.6443878197751993, 'w2': 0.05751796124266395}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:56,343] Trial 42 finished with value: 0.01583160776644945 and parameters: {'w1': 0.6658949497250705, 'w2': 0.041825497331848205}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:56,548] Trial 43 finished with value: 0.01583233866840601 and parameters: {'w1': 0.7886222532029799, 'w2': 0.12787559547864152}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:56,756] Trial 44 finished with value: 0.015833649039268493 and parameters: {'w1': 0.5625173295624957, 'w2': 0.0056300359598183275}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:56,960] Trial 45 finished with value: 0.015843936800956727 and parameters: {'w1': 0.6422265784100034, 'w2': 0.23715334414916678}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:57,159] Trial 46 finished with value: 0.01583133600652218 and parameters: {'w1': 0.4429597066002341, 'w2': 0.04795765051226749}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:57,360] Trial 47 finished with value: 0.015983797237277032 and parameters: {'w1': 0.3096241926510387, 'w2': 0.8322196161454605}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:57,562] Trial 48 finished with value: 0.01583136208355427 and parameters: {'w1': 0.43637929631786176, 'w2': 0.04876237349556968}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:57,767] Trial 49 finished with value: 0.015831387601792812 and parameters: {'w1': 0.3447178299436466, 'w2': 0.03948114064442899}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:57,976] Trial 50 finished with value: 0.01584763638675213 and parameters: {'w1': 0.44526004116478224, 'w2': 0.18619655967191084}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:58,178] Trial 51 finished with value: 0.01583168637007475 and parameters: {'w1': 0.363526320276699, 'w2': 0.049241153827432944}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:58,377] Trial 52 finished with value: 0.015833214670419694 and parameters: {'w1': 0.3280023291133287, 'w2': 0.005824693886888076}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:58,575] Trial 53 finished with value: 0.015831323526799678 and parameters: {'w1': 0.42329702142962816, 'w2': 0.036381482049312554}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:58,775] Trial 54 finished with value: 0.015834791772067546 and parameters: {'w1': 0.5233242247268179, 'w2': 0.11716424419024388}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:58,997] Trial 55 finished with value: 0.015842261910438537 and parameters: {'w1': 0.4151298794928892, 'w2': 0.14365809956697415}. Best is trial 41 with value: 0.01583130843937397.\n[I 2020-10-01 05:27:59,217] Trial 56 finished with value: 0.015831296890974046 and parameters: {'w1': 0.4423714064703775, 'w2': 0.0419392056700127}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:27:59,421] Trial 57 finished with value: 0.01583312898874283 and parameters: {'w1': 0.2662503265539544, 'w2': 0.005170548427121835}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:27:59,627] Trial 58 finished with value: 0.015834005177021028 and parameters: {'w1': 0.5250291385886094, 'w2': 0.1086546482273745}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:27:59,831] Trial 59 finished with value: 0.015831786580383776 and parameters: {'w1': 0.5702401664585635, 'w2': 0.031314123644055405}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:00,033] Trial 60 finished with value: 0.015849154256284238 and parameters: {'w1': 0.4571404058046067, 'w2': 0.20001994024775985}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:00,239] Trial 61 finished with value: 0.015831713378429414 and parameters: {'w1': 0.42416309308723865, 'w2': 0.058061737250783854}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:00,434] Trial 62 finished with value: 0.0158337177708745 and parameters: {'w1': 0.3799435211285264, 'w2': 0.003385413436908187}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:00,632] Trial 63 finished with value: 0.015836546756327154 and parameters: {'w1': 0.48857896222107366, 'w2': 0.12565659489111464}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:00,825] Trial 64 finished with value: 0.01583143472671509 and parameters: {'w1': 0.5845112408219807, 'w2': 0.06964770256105586}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:01,026] Trial 65 finished with value: 0.016113173961639405 and parameters: {'w1': 0.006645953594433818, 'w2': 0.16428818019098473}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:01,229] Trial 66 finished with value: 0.015831896848976613 and parameters: {'w1': 0.5338406065689996, 'w2': 0.0270778064147248}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:01,430] Trial 67 finished with value: 0.015834023244678974 and parameters: {'w1': 0.4438327190176435, 'w2': 0.09202370556237299}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:01,633] Trial 68 finished with value: 0.0158316882327199 and parameters: {'w1': 0.7005137233703503, 'w2': 0.041352536384419096}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:01,834] Trial 69 finished with value: 0.01583885122090578 and parameters: {'w1': 0.3950950952056296, 'w2': 0.11675411874129299}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:02,038] Trial 70 finished with value: 0.01597197912633419 and parameters: {'w1': 0.1952928251683022, 'w2': 0.46277909187145816}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:02,238] Trial 71 finished with value: 0.015831846743822098 and parameters: {'w1': 0.32866898608214823, 'w2': 0.04704785849851283}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:02,443] Trial 72 finished with value: 0.01583398673683405 and parameters: {'w1': 0.355986200151647, 'w2': 0.07351068485154952}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:02,645] Trial 73 finished with value: 0.015831653773784638 and parameters: {'w1': 0.42226331886019286, 'w2': 0.025601106732616948}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:02,851] Trial 74 finished with value: 0.01584208309650421 and parameters: {'w1': 0.29178953686254533, 'w2': 0.10024162435129447}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:03,060] Trial 75 finished with value: 0.015834078192710876 and parameters: {'w1': 0.508164286007498, 'w2': 0.001643915521382197}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:03,274] Trial 76 finished with value: 0.015832068212330342 and parameters: {'w1': 0.4713788753641195, 'w2': 0.07185372480770526}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:03,479] Trial 77 finished with value: 0.015862270444631576 and parameters: {'w1': 0.25766140408788796, 'w2': 0.15386284032795577}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:03,682] Trial 78 finished with value: 0.015831760317087173 and parameters: {'w1': 0.6586920772563692, 'w2': 0.036797865957454386}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:03,884] Trial 79 finished with value: 0.015847600251436233 and parameters: {'w1': 0.3437478333893678, 'w2': 0.14358400020830672}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:04,117] Trial 80 finished with value: 0.01586702261120081 and parameters: {'w1': 0.09262911830894166, 'w2': 0.06055565744001231}. Best is trial 56 with value: 0.015831296890974046.\n","name":"stderr"},{"output_type":"stream","text":"[I 2020-10-01 05:28:04,410] Trial 81 finished with value: 0.01583162136375904 and parameters: {'w1': 0.583235242664516, 'w2': 0.0769308884897684}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:04,693] Trial 82 finished with value: 0.015831921622157095 and parameters: {'w1': 0.6998589857846493, 'w2': 0.1024417502806031}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:04,908] Trial 83 finished with value: 0.015832125395536422 and parameters: {'w1': 0.5442801766683689, 'w2': 0.02350676135964928}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:05,136] Trial 84 finished with value: 0.015831311233341694 and parameters: {'w1': 0.6471061284315204, 'w2': 0.05738225057231993}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:05,345] Trial 85 finished with value: 0.015831412002444267 and parameters: {'w1': 0.6414419906292201, 'w2': 0.04842448247383075}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:05,552] Trial 86 finished with value: 0.015832164138555527 and parameters: {'w1': 0.7788287105033125, 'w2': 0.1214927294441226}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:05,762] Trial 87 finished with value: 0.01589489318430424 and parameters: {'w1': 0.5973305310149113, 'w2': 0.5963043948915054}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:05,971] Trial 88 finished with value: 0.015833764523267745 and parameters: {'w1': 0.7164453075445513, 'w2': 0.005819255598742926}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:06,178] Trial 89 finished with value: 0.015919797122478485 and parameters: {'w1': 0.40002721606948655, 'w2': 0.5402859777087797}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:06,379] Trial 90 finished with value: 0.015959837660193443 and parameters: {'w1': 0.4450884543615758, 'w2': 0.9277102761542351}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:06,583] Trial 91 finished with value: 0.015831464901566505 and parameters: {'w1': 0.681479924572958, 'w2': 0.048686984874363876}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:06,795] Trial 92 finished with value: 0.015831728093326093 and parameters: {'w1': 0.653232108286626, 'w2': 0.08988396543096894}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:07,101] Trial 93 finished with value: 0.015832049027085304 and parameters: {'w1': 0.7300460578367615, 'w2': 0.033281050781281366}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:07,303] Trial 94 finished with value: 0.01583795212209225 and parameters: {'w1': 0.6420154163598389, 'w2': 0.18044047362267968}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:07,494] Trial 95 finished with value: 0.01583225131034851 and parameters: {'w1': 0.504754807104805, 'w2': 0.019926825390069965}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:07,691] Trial 96 finished with value: 0.015831395611166955 and parameters: {'w1': 0.5494638890210084, 'w2': 0.06343307771959013}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:07,888] Trial 97 finished with value: 0.015835868753492834 and parameters: {'w1': 0.5492963992323473, 'w2': 0.13452901112765375}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:08,087] Trial 98 finished with value: 0.01583182942122221 and parameters: {'w1': 0.47619618655199614, 'w2': 0.06779982728187728}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:08,293] Trial 99 finished with value: 0.015837639383971692 and parameters: {'w1': 0.37303139762776066, 'w2': 0.1029166268361138}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:08,493] Trial 100 finished with value: 0.015842224843800067 and parameters: {'w1': 0.7584029843804918, 'w2': 0.26205849022815103}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:08,693] Trial 101 finished with value: 0.015831375122070314 and parameters: {'w1': 0.6300059626024528, 'w2': 0.049814386037715416}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:08,894] Trial 102 finished with value: 0.015834104269742966 and parameters: {'w1': 0.6053461418000581, 'w2': 0.0017022684748108086}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:09,107] Trial 103 finished with value: 0.015831507556140424 and parameters: {'w1': 0.6864307899852353, 'w2': 0.08555420977737574}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:09,307] Trial 104 finished with value: 0.015831335633993148 and parameters: {'w1': 0.5175904422949797, 'w2': 0.05587019239507722}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:09,507] Trial 105 finished with value: 0.015929073467850684 and parameters: {'w1': 0.43821128130476766, 'w2': 0.6567071013005836}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:09,712] Trial 106 finished with value: 0.015832682326436042 and parameters: {'w1': 0.6301370440006384, 'w2': 0.01809868448057108}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:09,906] Trial 107 finished with value: 0.015834684111177923 and parameters: {'w1': 0.5134497592002836, 'w2': 0.11381124926056355}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:10,110] Trial 108 finished with value: 0.01583131868392229 and parameters: {'w1': 0.5888289117857647, 'w2': 0.051197068015434256}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:10,310] Trial 109 finished with value: 0.01583175528794527 and parameters: {'w1': 0.5966750069143415, 'w2': 0.08289158690682463}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:10,507] Trial 110 finished with value: 0.0158337427303195 and parameters: {'w1': 0.80714087157632, 'w2': 0.16214972033580305}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:10,707] Trial 111 finished with value: 0.015831360965967177 and parameters: {'w1': 0.4594407872995972, 'w2': 0.05125285211026687}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:10,904] Trial 112 finished with value: 0.015831305459141732 and parameters: {'w1': 0.577940526691104, 'w2': 0.052262495162124625}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:11,106] Trial 113 finished with value: 0.0158321388065815 and parameters: {'w1': 0.4942592046730853, 'w2': 0.02113819550899184}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:11,305] Trial 114 finished with value: 0.0158317307010293 and parameters: {'w1': 0.46521696727909, 'w2': 0.06410070437570914}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:11,505] Trial 115 finished with value: 0.01583280637860298 and parameters: {'w1': 0.570079729255639, 'w2': 0.1006847625193189}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:11,706] Trial 116 finished with value: 0.015833930112421513 and parameters: {'w1': 0.4105031900674451, 'w2': 0.002260324890177537}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:11,905] Trial 117 finished with value: 0.015831396356225012 and parameters: {'w1': 0.5287377926275079, 'w2': 0.04068231384753428}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:12,130] Trial 118 finished with value: 0.01583715435117483 and parameters: {'w1': 0.4841697803074713, 'w2': 0.12964755195118538}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:12,330] Trial 119 finished with value: 0.015832033567130567 and parameters: {'w1': 0.42706027809776065, 'w2': 0.06448901979486207}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:12,531] Trial 120 finished with value: 0.015833112038671972 and parameters: {'w1': 0.45839815078302015, 'w2': 0.0848719713987341}. Best is trial 56 with value: 0.015831296890974046.\n","name":"stderr"},{"output_type":"stream","text":"[I 2020-10-01 05:28:12,727] Trial 121 finished with value: 0.015831311978399754 and parameters: {'w1': 0.5800224234721768, 'w2': 0.05123989317813242}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:12,928] Trial 122 finished with value: 0.015832495503127576 and parameters: {'w1': 0.6162171775039145, 'w2': 0.020396675910044557}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:13,132] Trial 123 finished with value: 0.015831358544528485 and parameters: {'w1': 0.5597631169067764, 'w2': 0.04522663997208413}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:13,345] Trial 124 finished with value: 0.01583180371671915 and parameters: {'w1': 0.5739826768895269, 'w2': 0.0310952981165696}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:13,543] Trial 125 finished with value: 0.015834144689142703 and parameters: {'w1': 0.5548330965246557, 'w2': 0.001237047697630278}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:13,751] Trial 126 finished with value: 0.015833052061498164 and parameters: {'w1': 0.590377244046997, 'w2': 0.10831975786421484}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:14,045] Trial 127 finished with value: 0.015831444412469864 and parameters: {'w1': 0.6682105667511841, 'w2': 0.08013498360567976}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:14,300] Trial 128 finished with value: 0.015831308253109456 and parameters: {'w1': 0.5257531044883759, 'w2': 0.053952404136361085}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:14,503] Trial 129 finished with value: 0.015831373259425165 and parameters: {'w1': 0.529810560947023, 'w2': 0.05999466590984025}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:14,703] Trial 130 finished with value: 0.01583156380802393 and parameters: {'w1': 0.5099826031816572, 'w2': 0.03326643199768721}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:14,908] Trial 131 finished with value: 0.015831298567354678 and parameters: {'w1': 0.5718913054522387, 'w2': 0.055659402670907736}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:15,144] Trial 132 finished with value: 0.015832328237593174 and parameters: {'w1': 0.5698594187012586, 'w2': 0.09219296166808116}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:15,443] Trial 133 finished with value: 0.015832670032978058 and parameters: {'w1': 0.5995788596322693, 'w2': 0.01738680759664512}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:15,732] Trial 134 finished with value: 0.01583162471652031 and parameters: {'w1': 0.5402132261142716, 'w2': 0.07136127974103125}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:15,950] Trial 135 finished with value: 0.015834175422787665 and parameters: {'w1': 0.6216135955511916, 'w2': 0.0010939173003392116}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:16,254] Trial 136 finished with value: 0.01583607420325279 and parameters: {'w1': 0.58211969053674, 'w2': 0.14475714193959902}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:16,454] Trial 137 finished with value: 0.015832920745015144 and parameters: {'w1': 0.6565984141957153, 'w2': 0.11811572983006935}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:16,663] Trial 138 finished with value: 0.0158314710482955 and parameters: {'w1': 0.5580134456790415, 'w2': 0.03959576303587818}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:16,875] Trial 139 finished with value: 0.015831304527819157 and parameters: {'w1': 0.6069917551894808, 'w2': 0.055035967705422725}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:17,082] Trial 140 finished with value: 0.015831612795591355 and parameters: {'w1': 0.6855028902285624, 'w2': 0.09006649222322605}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:17,297] Trial 141 finished with value: 0.01583129782229662 and parameters: {'w1': 0.6044363866720677, 'w2': 0.056366038807275476}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:17,510] Trial 142 finished with value: 0.01585754081606865 and parameters: {'w1': 0.6047920840075832, 'w2': 0.32693421200215134}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:17,719] Trial 143 finished with value: 0.015831322595477103 and parameters: {'w1': 0.6383837555191215, 'w2': 0.05494084113259014}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:17,932] Trial 144 finished with value: 0.015831299312412738 and parameters: {'w1': 0.6539471448603803, 'w2': 0.06430102630136912}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:18,154] Trial 145 finished with value: 0.0158313462510705 and parameters: {'w1': 0.6467509165213985, 'w2': 0.07076546631442299}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:18,356] Trial 146 finished with value: 0.015832721814513208 and parameters: {'w1': 0.7200339185796881, 'w2': 0.020036371522145477}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:18,556] Trial 147 finished with value: 0.01583180818706751 and parameters: {'w1': 0.6674489006009636, 'w2': 0.09442536868350081}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:18,756] Trial 148 finished with value: 0.015831301175057887 and parameters: {'w1': 0.6259320909930428, 'w2': 0.06271746990345461}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:18,957] Trial 149 finished with value: 0.015832936391234398 and parameters: {'w1': 0.6344258844382893, 'w2': 0.11441275186690891}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:19,159] Trial 150 finished with value: 0.015831928141415118 and parameters: {'w1': 0.6160955703046291, 'w2': 0.030572047162943018}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:19,360] Trial 151 finished with value: 0.015831329859793186 and parameters: {'w1': 0.5844348138894984, 'w2': 0.06261386973748773}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:19,569] Trial 152 finished with value: 0.015831304155290125 and parameters: {'w1': 0.6989366502138151, 'w2': 0.07087311473761067}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:19,779] Trial 153 finished with value: 0.015831359848380088 and parameters: {'w1': 0.6993631336728126, 'w2': 0.07790333875968788}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:19,989] Trial 154 finished with value: 0.01583140641450882 and parameters: {'w1': 0.6459267662026018, 'w2': 0.04899692583624264}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:20,199] Trial 155 finished with value: 0.015834046714007854 and parameters: {'w1': 0.6189105667159127, 'w2': 0.00230141469517043}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:20,405] Trial 156 finished with value: 0.01583349723368883 and parameters: {'w1': 0.6743658084671423, 'w2': 0.13145580925645928}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:20,614] Trial 157 finished with value: 0.015832425281405448 and parameters: {'w1': 0.5996872984745504, 'w2': 0.09893001014484215}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:20,820] Trial 158 finished with value: 0.015831880457699298 and parameters: {'w1': 0.6351900327985187, 'w2': 0.032580132905111116}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:21,022] Trial 159 finished with value: 0.015831324085593224 and parameters: {'w1': 0.6581220128026454, 'w2': 0.0566023707999191}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:21,231] Trial 160 finished with value: 0.01583153009414673 and parameters: {'w1': 0.5855301017081485, 'w2': 0.07387578577298683}. Best is trial 56 with value: 0.015831296890974046.\n","name":"stderr"},{"output_type":"stream","text":"[I 2020-10-01 05:28:21,433] Trial 161 finished with value: 0.015861270390450953 and parameters: {'w1': 0.6546757147546008, 'w2': 0.38314579708750796}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:21,640] Trial 162 finished with value: 0.01583131607621908 and parameters: {'w1': 0.6178526164341911, 'w2': 0.053907598499400626}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:21,846] Trial 163 finished with value: 0.015834129974246026 and parameters: {'w1': 0.6019009244824292, 'w2': 0.001474979550449361}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:22,051] Trial 164 finished with value: 0.01583164036273956 and parameters: {'w1': 0.6159959029945407, 'w2': 0.03773306557998737}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:22,260] Trial 165 finished with value: 0.01583279948681593 and parameters: {'w1': 0.6951930744846393, 'w2': 0.01817789576645632}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:22,465] Trial 166 finished with value: 0.015831300429999827 and parameters: {'w1': 0.6293011372750855, 'w2': 0.05822749595294382}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:22,674] Trial 167 finished with value: 0.01583157032728195 and parameters: {'w1': 0.6369956273272758, 'w2': 0.08202127953811528}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:22,888] Trial 168 finished with value: 0.0158313462510705 and parameters: {'w1': 0.6729198355807433, 'w2': 0.05552339851444078}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:23,095] Trial 169 finished with value: 0.015833252109587193 and parameters: {'w1': 0.570932298866268, 'w2': 0.1077570223828477}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:23,321] Trial 170 finished with value: 0.015831326134502888 and parameters: {'w1': 0.6217176238326422, 'w2': 0.06609450627203446}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:23,528] Trial 171 finished with value: 0.015831701830029486 and parameters: {'w1': 0.5957377771934189, 'w2': 0.03479068948976802}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:23,735] Trial 172 finished with value: 0.015831298753619195 and parameters: {'w1': 0.5403414739920991, 'w2': 0.050838430492358214}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:23,949] Trial 173 finished with value: 0.01583215333521366 and parameters: {'w1': 0.5416899266675334, 'w2': 0.08429510639217899}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:24,156] Trial 174 finished with value: 0.015831300243735313 and parameters: {'w1': 0.5603206342410199, 'w2': 0.05178554812651012}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:24,368] Trial 175 finished with value: 0.01583209801465273 and parameters: {'w1': 0.548705117113903, 'w2': 0.024147070029841674}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:24,577] Trial 176 finished with value: 0.01591925509274006 and parameters: {'w1': 0.5772814555459098, 'w2': 0.7748859039180576}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:24,780] Trial 177 finished with value: 0.01583132762461901 and parameters: {'w1': 0.56225062977932, 'w2': 0.05996986659162354}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:24,984] Trial 178 finished with value: 0.015833251364529132 and parameters: {'w1': 0.5347947104464522, 'w2': 0.10092067660602741}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:25,192] Trial 179 finished with value: 0.01583151612430811 and parameters: {'w1': 0.6118849247736337, 'w2': 0.04161089099332299}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:25,395] Trial 180 finished with value: 0.015832899138331413 and parameters: {'w1': 0.5872310709661628, 'w2': 0.014088515470755944}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:25,603] Trial 181 finished with value: 0.015831307508051395 and parameters: {'w1': 0.6398187623819834, 'w2': 0.05739695025389799}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:25,814] Trial 182 finished with value: 0.015831479616463185 and parameters: {'w1': 0.6281351387921749, 'w2': 0.07705124149976966}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:26,019] Trial 183 finished with value: 0.01583137046545744 and parameters: {'w1': 0.6031656510057716, 'w2': 0.04792398360778091}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:26,307] Trial 184 finished with value: 0.015831619687378406 and parameters: {'w1': 0.5605100041156355, 'w2': 0.07387977315634349}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:26,584] Trial 185 finished with value: 0.015831948816776277 and parameters: {'w1': 0.6552378613731108, 'w2': 0.09667045568168756}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:26,847] Trial 186 finished with value: 0.015832571126520634 and parameters: {'w1': 0.5821384974471835, 'w2': 0.018203544577137437}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:27,073] Trial 187 finished with value: 0.01583414152264595 and parameters: {'w1': 0.5267214339564555, 'w2': 0.0011962810455810255}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:27,285] Trial 188 finished with value: 0.01583139318972826 and parameters: {'w1': 0.6810057091934556, 'w2': 0.05252863238237388}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:27,497] Trial 189 finished with value: 0.01583160776644945 and parameters: {'w1': 0.6117187480460846, 'w2': 0.03841733405051342}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:27,710] Trial 190 finished with value: 0.01583136562258005 and parameters: {'w1': 0.6339501726450367, 'w2': 0.07109330848194809}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:27,916] Trial 191 finished with value: 0.015831316448748113 and parameters: {'w1': 0.6386439919899735, 'w2': 0.05583658308592932}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:28,120] Trial 192 finished with value: 0.01583129893988371 and parameters: {'w1': 0.5949247209710644, 'w2': 0.05808815569825998}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:28,326] Trial 193 finished with value: 0.01583151798695326 and parameters: {'w1': 0.6480383278362527, 'w2': 0.08127910546003045}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:28,525] Trial 194 finished with value: 0.015831941924989223 and parameters: {'w1': 0.6696962751359705, 'w2': 0.03286075637375263}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:28,737] Trial 195 finished with value: 0.015833047218620777 and parameters: {'w1': 0.6193748384158888, 'w2': 0.113560261556003}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:28,945] Trial 196 finished with value: 0.015831376798450945 and parameters: {'w1': 0.7061988719450321, 'w2': 0.055671042704693426}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:29,157] Trial 197 finished with value: 0.01583229973912239 and parameters: {'w1': 0.5603294185278582, 'w2': 0.09008628506484617}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:29,361] Trial 198 finished with value: 0.01583132762461901 and parameters: {'w1': 0.6005401916567342, 'w2': 0.0641189854084039}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:29,566] Trial 199 finished with value: 0.015832295268774034 and parameters: {'w1': 0.49574655768821546, 'w2': 0.018939999064981138}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:29,777] Trial 200 finished with value: 0.015831736475229265 and parameters: {'w1': 0.6353862308098888, 'w2': 0.03616141894135557}. Best is trial 56 with value: 0.015831296890974046.\n","name":"stderr"},{"output_type":"stream","text":"[I 2020-10-01 05:28:29,988] Trial 201 finished with value: 0.015831297263503075 and parameters: {'w1': 0.5824383411770898, 'w2': 0.05546871086728511}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:30,290] Trial 202 finished with value: 0.015831402316689492 and parameters: {'w1': 0.575829676331002, 'w2': 0.06689456823510241}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:30,496] Trial 203 finished with value: 0.01583139207214117 and parameters: {'w1': 0.5940952625470906, 'w2': 0.045868424780723394}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:30,704] Trial 204 finished with value: 0.015832225419580938 and parameters: {'w1': 0.5467440270462368, 'w2': 0.08647647812383294}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:30,918] Trial 205 finished with value: 0.015831305645406246 and parameters: {'w1': 0.6192036521377525, 'w2': 0.06285614911963139}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:31,127] Trial 206 finished with value: 0.015834076330065727 and parameters: {'w1': 0.6122764208796694, 'w2': 0.001994481517966204}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:31,334] Trial 207 finished with value: 0.015832830965518952 and parameters: {'w1': 0.5707396373392422, 'w2': 0.10121548743479972}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:31,537] Trial 208 finished with value: 0.015832138434052467 and parameters: {'w1': 0.5917427190633949, 'w2': 0.025320451954082522}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:31,742] Trial 209 finished with value: 0.01583140194416046 and parameters: {'w1': 0.6531786520357232, 'w2': 0.07589301715933001}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:31,951] Trial 210 finished with value: 0.01583581529557705 and parameters: {'w1': 0.5122061353980374, 'w2': 0.1249199883560855}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:32,166] Trial 211 finished with value: 0.01583129893988371 and parameters: {'w1': 0.6237592865187143, 'w2': 0.058785507754031706}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:32,377] Trial 212 finished with value: 0.015831458568572997 and parameters: {'w1': 0.627874112724094, 'w2': 0.045174046274342336}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:32,591] Trial 213 finished with value: 0.01583136785775423 and parameters: {'w1': 0.6134249917622036, 'w2': 0.06906527140830296}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:32,805] Trial 214 finished with value: 0.015831713750958442 and parameters: {'w1': 0.5736808690165943, 'w2': 0.03324283250895152}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:33,019] Trial 215 finished with value: 0.01583131719380617 and parameters: {'w1': 0.5458771262774946, 'w2': 0.057257764799918315}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:33,245] Trial 216 finished with value: 0.015831672959029673 and parameters: {'w1': 0.6569888336863855, 'w2': 0.08860791858252273}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:33,453] Trial 217 finished with value: 0.01583259366452694 and parameters: {'w1': 0.5989926482386434, 'w2': 0.01841695883588928}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:33,664] Trial 218 finished with value: 0.01583130806684494 and parameters: {'w1': 0.6857719446316802, 'w2': 0.0615640164038691}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:33,871] Trial 219 finished with value: 0.01583129782229662 and parameters: {'w1': 0.7487624614011105, 'w2': 0.07069055475428827}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:34,085] Trial 220 finished with value: 0.015831783041357995 and parameters: {'w1': 0.7481390962344574, 'w2': 0.1049516424704128}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:34,297] Trial 221 finished with value: 0.015831297636032103 and parameters: {'w1': 0.7334230891172049, 'w2': 0.07099038954806539}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:34,504] Trial 222 finished with value: 0.015831334888935088 and parameters: {'w1': 0.7204946110795043, 'w2': 0.07765844314102167}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:34,712] Trial 223 finished with value: 0.015831345692276955 and parameters: {'w1': 0.8029587437610093, 'w2': 0.06626817340926612}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:34,923] Trial 224 finished with value: 0.01583177875727415 and parameters: {'w1': 0.757120853211986, 'w2': 0.04180338831798845}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:35,134] Trial 225 finished with value: 0.01583145260810852 and parameters: {'w1': 0.6893144299286738, 'w2': 0.08314353776832421}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:35,345] Trial 226 finished with value: 0.015831328555941583 and parameters: {'w1': 0.7430409385920868, 'w2': 0.0631559853398805}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:35,550] Trial 227 finished with value: 0.01583174280822277 and parameters: {'w1': 0.7177006416924006, 'w2': 0.04063029892325189}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:35,750] Trial 228 finished with value: 0.015831488370895385 and parameters: {'w1': 0.7808743086398552, 'w2': 0.09624465848276728}. Best is trial 56 with value: 0.015831296890974046.\n[I 2020-10-01 05:28:35,955] Trial 229 finished with value: 0.01583129558712244 and parameters: {'w1': 0.7294536413552165, 'w2': 0.06924639830655917}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:36,162] Trial 230 finished with value: 0.015831308625638484 and parameters: {'w1': 0.7351447843664115, 'w2': 0.0754700088329498}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:36,366] Trial 231 finished with value: 0.01583129819482565 and parameters: {'w1': 0.7410832015065423, 'w2': 0.06977729549553835}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:36,567] Trial 232 finished with value: 0.015831299498677252 and parameters: {'w1': 0.7647689712806802, 'w2': 0.07623539726176254}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:36,769] Trial 233 finished with value: 0.015831444412469864 and parameters: {'w1': 0.7725752378530346, 'w2': 0.09273403017668244}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:36,975] Trial 234 finished with value: 0.015831825882196428 and parameters: {'w1': 0.8342502623816764, 'w2': 0.1186436621833512}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:37,257] Trial 235 finished with value: 0.01583130080252886 and parameters: {'w1': 0.7296515572436169, 'w2': 0.06723065620632494}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:37,551] Trial 236 finished with value: 0.01583130769431591 and parameters: {'w1': 0.7621553833646159, 'w2': 0.06852326799730447}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:37,825] Trial 237 finished with value: 0.01583131346851587 and parameters: {'w1': 0.7289559346158517, 'w2': 0.07599261332313212}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:38,046] Trial 238 finished with value: 0.01583178136497736 and parameters: {'w1': 0.7630150743334605, 'w2': 0.10698049143284767}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:38,255] Trial 239 finished with value: 0.01583132315427065 and parameters: {'w1': 0.797626599428656, 'w2': 0.06856015823563381}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:38,455] Trial 240 finished with value: 0.01583142075687647 and parameters: {'w1': 0.7400469235512701, 'w2': 0.08725766846286154}. Best is trial 229 with value: 0.01583129558712244.\n","name":"stderr"},{"output_type":"stream","text":"[I 2020-10-01 05:28:38,664] Trial 241 finished with value: 0.015831544250249862 and parameters: {'w1': 0.7595837518227481, 'w2': 0.05039006967737436}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:38,881] Trial 242 finished with value: 0.015832051075994967 and parameters: {'w1': 0.7159604017113848, 'w2': 0.032575421397411146}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:39,186] Trial 243 finished with value: 0.01583133712410927 and parameters: {'w1': 0.7374806416552472, 'w2': 0.06179925432511173}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:39,397] Trial 244 finished with value: 0.0158316645771265 and parameters: {'w1': 0.7861138007203794, 'w2': 0.047236875253375846}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:39,611] Trial 245 finished with value: 0.01583130657672882 and parameters: {'w1': 0.7016023419382025, 'w2': 0.07125946683043004}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:39,821] Trial 246 finished with value: 0.0158315047621727 and parameters: {'w1': 0.6994958074813511, 'w2': 0.08706349340218944}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:40,026] Trial 247 finished with value: 0.01583130322396755 and parameters: {'w1': 0.7607589805810504, 'w2': 0.06927623208900391}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:40,234] Trial 248 finished with value: 0.015831745229661465 and parameters: {'w1': 0.7616112070175984, 'w2': 0.10542430668222823}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:40,444] Trial 249 finished with value: 0.015831298753619195 and parameters: {'w1': 0.7774492691410094, 'w2': 0.07554357817416982}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:40,654] Trial 250 finished with value: 0.01583228223025799 and parameters: {'w1': 0.7859780964202667, 'w2': 0.030357358493016785}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:40,862] Trial 251 finished with value: 0.01583135351538658 and parameters: {'w1': 0.8185460240154449, 'w2': 0.09057617345509422}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:41,073] Trial 252 finished with value: 0.01583288740366697 and parameters: {'w1': 0.732467721742194, 'w2': 0.1310485223170877}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:41,283] Trial 253 finished with value: 0.015831397846341133 and parameters: {'w1': 0.7125736111290077, 'w2': 0.08240435730936237}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:41,495] Trial 254 finished with value: 0.015831810422241688 and parameters: {'w1': 0.7755282998323134, 'w2': 0.041841625842762104}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:41,710] Trial 255 finished with value: 0.01583131290972233 and parameters: {'w1': 0.7477487616300198, 'w2': 0.06589856990643103}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:41,923] Trial 256 finished with value: 0.015832577645778657 and parameters: {'w1': 0.7298398726365174, 'w2': 0.022722977093589954}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:42,138] Trial 257 finished with value: 0.015832330286502837 and parameters: {'w1': 0.7072966453284507, 'w2': 0.11449074791942795}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:42,354] Trial 258 finished with value: 0.015831467509269715 and parameters: {'w1': 0.7509499639049058, 'w2': 0.0535088362331638}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:42,561] Trial 259 finished with value: 0.015831299871206284 and parameters: {'w1': 0.7677702137226728, 'w2': 0.07613702229549787}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:42,773] Trial 260 finished with value: 0.015831520780920982 and parameters: {'w1': 0.771528509525551, 'w2': 0.09689212863625551}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:42,989] Trial 261 finished with value: 0.015831300988793373 and parameters: {'w1': 0.8103154642149565, 'w2': 0.07436154663424822}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:43,348] Trial 262 finished with value: 0.01583129707723856 and parameters: {'w1': 0.8410971708789632, 'w2': 0.08082491335376672}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:43,662] Trial 263 finished with value: 0.015831362269818784 and parameters: {'w1': 0.8228210902323261, 'w2': 0.09201422419004031}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:43,981] Trial 264 finished with value: 0.015831637009978295 and parameters: {'w1': 0.8141599359770154, 'w2': 0.10814609414753096}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:44,218] Trial 265 finished with value: 0.01583130657672882 and parameters: {'w1': 0.806452867375391, 'w2': 0.08197733116926742}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:44,423] Trial 266 finished with value: 0.015832351893186568 and parameters: {'w1': 0.8414687660394442, 'w2': 0.13682670257495672}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:44,632] Trial 267 finished with value: 0.01583254002034664 and parameters: {'w1': 0.7738700464065876, 'w2': 0.024787513441331337}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:44,841] Trial 268 finished with value: 0.015832004137337208 and parameters: {'w1': 0.849056185106265, 'w2': 0.039928721875593785}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:45,127] Trial 269 finished with value: 0.015831323340535164 and parameters: {'w1': 0.8939920525819918, 'w2': 0.07692576143162276}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:45,417] Trial 270 finished with value: 0.015831802040338516 and parameters: {'w1': 0.8688705884919043, 'w2': 0.047127216501681515}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:45,626] Trial 271 finished with value: 0.015833227895200253 and parameters: {'w1': 0.7980019685371854, 'w2': 0.013967484368986802}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:45,833] Trial 272 finished with value: 0.015831989981234074 and parameters: {'w1': 0.7813260270777235, 'w2': 0.11659031870955198}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:46,046] Trial 273 finished with value: 0.015831305645406246 and parameters: {'w1': 0.8642241906541558, 'w2': 0.0778851267135933}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:46,266] Trial 274 finished with value: 0.015831814520061015 and parameters: {'w1': 0.7440121044360684, 'w2': 0.040018725151297924}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:46,470] Trial 275 finished with value: 0.015831551142036916 and parameters: {'w1': 0.7953761825580712, 'w2': 0.10143024941038653}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:46,675] Trial 276 finished with value: 0.015831332840025424 and parameters: {'w1': 0.7477345559931842, 'w2': 0.06316084052932706}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:46,880] Trial 277 finished with value: 0.01583136022090912 and parameters: {'w1': 0.7648093391819909, 'w2': 0.08520510918685378}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:47,091] Trial 278 finished with value: 0.015831429697573184 and parameters: {'w1': 0.8249687871177188, 'w2': 0.061083678392840055}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:47,305] Trial 279 finished with value: 0.015832074172794818 and parameters: {'w1': 0.7266121890565637, 'w2': 0.032492518035609125}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:47,513] Trial 280 finished with value: 0.015833955630660056 and parameters: {'w1': 0.757532747211457, 'w2': 0.0038599820022406917}. Best is trial 229 with value: 0.01583129558712244.\n","name":"stderr"},{"output_type":"stream","text":"[I 2020-10-01 05:28:47,718] Trial 281 finished with value: 0.01583130657672882 and parameters: {'w1': 0.7325411021689274, 'w2': 0.07441606289761721}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:47,921] Trial 282 finished with value: 0.015831602551043034 and parameters: {'w1': 0.7906517973950569, 'w2': 0.04984556296492356}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:48,127] Trial 283 finished with value: 0.015832560881972314 and parameters: {'w1': 0.564327250291566, 'w2': 0.09553088545615925}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:48,513] Trial 284 finished with value: 0.015832836180925368 and parameters: {'w1': 0.959960508441469, 'w2': 0.0243045687813715}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:48,815] Trial 285 finished with value: 0.015831508859992027 and parameters: {'w1': 0.7687820028413888, 'w2': 0.05269044797764995}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:49,080] Trial 286 finished with value: 0.015873915515840054 and parameters: {'w1': 0.7214012941152085, 'w2': 0.5311045972541698}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:49,400] Trial 287 finished with value: 0.01583415102213621 and parameters: {'w1': 0.5819721548535155, 'w2': 0.1223204046441248}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:49,701] Trial 288 finished with value: 0.015831299871206284 and parameters: {'w1': 0.8088839050272418, 'w2': 0.07440344237161663}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:49,957] Trial 289 finished with value: 0.015831442177295686 and parameters: {'w1': 0.8301023094746218, 'w2': 0.09947053987509556}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:50,167] Trial 290 finished with value: 0.015831296890974046 and parameters: {'w1': 0.8065397249657137, 'w2': 0.07700416585786805}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:50,406] Trial 291 finished with value: 0.01583131719380617 and parameters: {'w1': 0.8056468002527882, 'w2': 0.08441969804237444}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:50,618] Trial 292 finished with value: 0.015832929126918315 and parameters: {'w1': 0.7927747595780105, 'w2': 0.14280413030339106}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:50,835] Trial 293 finished with value: 0.01583187486976385 and parameters: {'w1': 0.785090657278398, 'w2': 0.11337684222234445}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:51,051] Trial 294 finished with value: 0.01583130769431591 and parameters: {'w1': 0.838800685012695, 'w2': 0.0754873918469924}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:51,270] Trial 295 finished with value: 0.015831323713064192 and parameters: {'w1': 0.8179037865065326, 'w2': 0.07042700219760369}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:51,488] Trial 296 finished with value: 0.015831375680863857 and parameters: {'w1': 0.863320343685746, 'w2': 0.09799671855998413}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:51,707] Trial 297 finished with value: 0.015831871330738066 and parameters: {'w1': 0.8095939966692003, 'w2': 0.04180707471790637}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:51,928] Trial 298 finished with value: 0.015831358917057513 and parameters: {'w1': 0.8852716190781914, 'w2': 0.07151060539936034}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:52,143] Trial 299 finished with value: 0.01583144161850214 and parameters: {'w1': 0.7577184491155423, 'w2': 0.09076178788860026}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:52,372] Trial 300 finished with value: 0.0158323235809803 and parameters: {'w1': 0.7373631180092146, 'w2': 0.11915123995993086}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:52,588] Trial 301 finished with value: 0.015831373259425165 and parameters: {'w1': 0.7737093220872904, 'w2': 0.06125289113102515}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:52,813] Trial 302 finished with value: 0.015832133032381533 and parameters: {'w1': 0.691492446176509, 'w2': 0.029714714612701375}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:53,029] Trial 303 finished with value: 0.015831308625638484 and parameters: {'w1': 0.7992892734920418, 'w2': 0.08192955346932651}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:53,264] Trial 304 finished with value: 0.015833199582993986 and parameters: {'w1': 0.7519495017828575, 'w2': 0.01355254022382938}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:53,488] Trial 305 finished with value: 0.01583173908293247 and parameters: {'w1': 0.8427353003618026, 'w2': 0.047834475988662195}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:53,703] Trial 306 finished with value: 0.01583442632108927 and parameters: {'w1': 0.7120464163116347, 'w2': 0.15395137352935992}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:53,924] Trial 307 finished with value: 0.01583166029304266 and parameters: {'w1': 0.7916679214736091, 'w2': 0.10613420968401252}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:54,162] Trial 308 finished with value: 0.01583129595965147 and parameters: {'w1': 0.6767065859200271, 'w2': 0.06470021834166732}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:54,375] Trial 309 finished with value: 0.015831314958631992 and parameters: {'w1': 0.6710477639844384, 'w2': 0.058870196116404566}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:54,587] Trial 310 finished with value: 0.015832042880356313 and parameters: {'w1': 0.8238537612194627, 'w2': 0.03770403001391627}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:54,800] Trial 311 finished with value: 0.01583137959241867 and parameters: {'w1': 0.7788512654190383, 'w2': 0.08865675948676516}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:55,015] Trial 312 finished with value: 0.015831362269818784 and parameters: {'w1': 0.7639853687400263, 'w2': 0.06143638752103216}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:55,229] Trial 313 finished with value: 0.015832538716495037 and parameters: {'w1': 0.6704082104208391, 'w2': 0.021518342678734842}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:55,445] Trial 314 finished with value: 0.01583129968494177 and parameters: {'w1': 0.8114975347819611, 'w2': 0.07549663990083098}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:55,661] Trial 315 finished with value: 0.015831967070698737 and parameters: {'w1': 0.8515310101714456, 'w2': 0.12627185291013548}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:55,880] Trial 316 finished with value: 0.01583152711391449 and parameters: {'w1': 0.8145997521030313, 'w2': 0.10260803255343852}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:56,089] Trial 317 finished with value: 0.015834089368581772 and parameters: {'w1': 0.8249883098096468, 'w2': 0.00252278898805168}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:56,310] Trial 318 finished with value: 0.01583169251680374 and parameters: {'w1': 0.796982652168344, 'w2': 0.04688971820293651}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:56,524] Trial 319 finished with value: 0.015831305459141732 and parameters: {'w1': 0.8728940663332876, 'w2': 0.07916001635333321}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:56,738] Trial 320 finished with value: 0.01585291437804699 and parameters: {'w1': 0.9232886363016632, 'w2': 0.4472116975880785}. Best is trial 229 with value: 0.01583129558712244.\n","name":"stderr"},{"output_type":"stream","text":"[I 2020-10-01 05:28:57,050] Trial 321 finished with value: 0.015832042694091795 and parameters: {'w1': 0.8427223835816078, 'w2': 0.038574455491624145}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:57,261] Trial 322 finished with value: 0.015832059644162656 and parameters: {'w1': 0.5529729735442466, 'w2': 0.08408791712386368}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:57,467] Trial 323 finished with value: 0.01583131533116102 and parameters: {'w1': 0.628853406777915, 'w2': 0.0552398432119922}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:57,674] Trial 324 finished with value: 0.01583244279026985 and parameters: {'w1': 0.5963570939566525, 'w2': 0.09870979692971649}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:57,896] Trial 325 finished with value: 0.015831320360302926 and parameters: {'w1': 0.7850125939574147, 'w2': 0.06792246640093937}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:58,107] Trial 326 finished with value: 0.015832591988146304 and parameters: {'w1': 0.8126019255749237, 'w2': 0.025010035936093446}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:58,417] Trial 327 finished with value: 0.015831603296101095 and parameters: {'w1': 0.7419565788715538, 'w2': 0.046722241724939675}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:58,698] Trial 328 finished with value: 0.015940314903855324 and parameters: {'w1': 0.5344040208841521, 'w2': 0.9051323561597331}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:58,990] Trial 329 finished with value: 0.015831417962908746 and parameters: {'w1': 0.647027137882583, 'w2': 0.07616576996970079}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:59,207] Trial 330 finished with value: 0.01583233568817377 and parameters: {'w1': 0.7122667645764641, 'w2': 0.11543011473686482}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:59,430] Trial 331 finished with value: 0.01583130583167076 and parameters: {'w1': 0.6804536523152366, 'w2': 0.06145068542812425}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:59,654] Trial 332 finished with value: 0.015832068771123885 and parameters: {'w1': 0.6117608523958493, 'w2': 0.09327525541987236}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:28:59,871] Trial 333 finished with value: 0.01583309005945921 and parameters: {'w1': 0.7745741984115037, 'w2': 0.015606124383429093}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:00,100] Trial 334 finished with value: 0.0158319141715765 and parameters: {'w1': 0.8345569526032169, 'w2': 0.04179286726400131}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:00,319] Trial 335 finished with value: 0.015831299126148224 and parameters: {'w1': 0.8027042361022179, 'w2': 0.0792038678509605}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:00,536] Trial 336 finished with value: 0.015832502953708173 and parameters: {'w1': 0.807975000747814, 'w2': 0.1352965276832489}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:00,755] Trial 337 finished with value: 0.015831569023430348 and parameters: {'w1': 0.7981852036341898, 'w2': 0.10273374166756152}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:00,974] Trial 338 finished with value: 0.0158312963321805 and parameters: {'w1': 0.853623584102182, 'w2': 0.08086541215246441}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:01,191] Trial 339 finished with value: 0.015831478871405125 and parameters: {'w1': 0.7352754102154208, 'w2': 0.09015581126177859}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:01,407] Trial 340 finished with value: 0.01583163198083639 and parameters: {'w1': 0.9111242358146775, 'w2': 0.1207640715517967}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:01,621] Trial 341 finished with value: 0.015831307508051395 and parameters: {'w1': 0.849423619050341, 'w2': 0.07606401194822825}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:01,835] Trial 342 finished with value: 0.01583164297044277 and parameters: {'w1': 0.8658465873928909, 'w2': 0.05290312690228696}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:02,046] Trial 343 finished with value: 0.01583220399916172 and parameters: {'w1': 0.8387801456845392, 'w2': 0.03425242369660776}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:02,262] Trial 344 finished with value: 0.01583176702260971 and parameters: {'w1': 0.7556131074557256, 'w2': 0.10543024893809376}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:02,479] Trial 345 finished with value: 0.015831350348889828 and parameters: {'w1': 0.7799699414925909, 'w2': 0.06394343165990059}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:02,690] Trial 346 finished with value: 0.015833961218595503 and parameters: {'w1': 0.5637276231120496, 'w2': 0.002826307710397366}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:02,902] Trial 347 finished with value: 0.0158314224332571 and parameters: {'w1': 0.7209648819848069, 'w2': 0.08516670740746121}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:03,115] Trial 348 finished with value: 0.015832234360277652 and parameters: {'w1': 0.820362479643437, 'w2': 0.032801108428660575}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:03,335] Trial 349 finished with value: 0.015845967642962932 and parameters: {'w1': 0.7474971302332205, 'w2': 0.2963301418359706}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:03,551] Trial 350 finished with value: 0.015911541134119033 and parameters: {'w1': 0.5888906588633168, 'w2': 0.7227507493695761}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:03,769] Trial 351 finished with value: 0.015831400640308857 and parameters: {'w1': 0.5120812153223674, 'w2': 0.05938689631154205}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:04,001] Trial 352 finished with value: 0.015831298567354678 and parameters: {'w1': 0.8864380546819924, 'w2': 0.08242257622190693}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:04,212] Trial 353 finished with value: 0.015831466764211655 and parameters: {'w1': 0.8659900629495713, 'w2': 0.10540675154671025}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:04,420] Trial 354 finished with value: 0.01583197619765997 and parameters: {'w1': 0.9262669668274969, 'w2': 0.13768951786023603}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:04,629] Trial 355 finished with value: 0.01583129893988371 and parameters: {'w1': 0.8947695200790713, 'w2': 0.08757330031333417}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:04,853] Trial 356 finished with value: 0.0158313000574708 and parameters: {'w1': 0.9068423328225967, 'w2': 0.08874877530536399}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:05,071] Trial 357 finished with value: 0.015832634083926676 and parameters: {'w1': 0.8893660740039488, 'w2': 0.15257555590776506}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:05,291] Trial 358 finished with value: 0.015831500478088855 and parameters: {'w1': 0.9427403735341918, 'w2': 0.11710394012799388}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:05,506] Trial 359 finished with value: 0.015831299498677252 and parameters: {'w1': 0.9057829372280242, 'w2': 0.08935794529212884}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:05,726] Trial 360 finished with value: 0.015831762179732322 and parameters: {'w1': 0.8808191333261571, 'w2': 0.12264056564004472}. Best is trial 229 with value: 0.01583129558712244.\n","name":"stderr"},{"output_type":"stream","text":"[I 2020-10-01 05:29:05,944] Trial 361 finished with value: 0.01583133954554796 and parameters: {'w1': 0.904466370357052, 'w2': 0.0982148692811535}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:06,158] Trial 362 finished with value: 0.01583319567143917 and parameters: {'w1': 0.8995356293568465, 'w2': 0.1684896969475136}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:06,372] Trial 363 finished with value: 0.015848333947360516 and parameters: {'w1': 0.9416296186457923, 'w2': 0.4021688667505292}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:06,589] Trial 364 finished with value: 0.015831298567354678 and parameters: {'w1': 0.8893587521587174, 'w2': 0.08295208746895776}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:06,899] Trial 365 finished with value: 0.015831313282251357 and parameters: {'w1': 0.8868201145361447, 'w2': 0.0919386468234964}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:07,109] Trial 366 finished with value: 0.01583129893988371 and parameters: {'w1': 0.8431873813527517, 'w2': 0.08245677683615324}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:07,325] Trial 367 finished with value: 0.015831430815160273 and parameters: {'w1': 0.9349539616093951, 'w2': 0.11110153090498832}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:07,538] Trial 368 finished with value: 0.01583129819482565 and parameters: {'w1': 0.8820640610547417, 'w2': 0.08221722072971888}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:07,756] Trial 369 finished with value: 0.01583199966698885 and parameters: {'w1': 0.909806320130003, 'w2': 0.13606058061454285}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:07,970] Trial 370 finished with value: 0.01583133973181248 and parameters: {'w1': 0.8742879742872128, 'w2': 0.09501850498518513}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:08,181] Trial 371 finished with value: 0.015831577964127062 and parameters: {'w1': 0.8851812991160555, 'w2': 0.11438856009553713}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:08,401] Trial 372 finished with value: 0.01583130154758692 and parameters: {'w1': 0.8733479622767086, 'w2': 0.08732556573049204}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:08,620] Trial 373 finished with value: 0.015831645205616952 and parameters: {'w1': 0.9173298912881858, 'w2': 0.05597167896395994}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:08,834] Trial 374 finished with value: 0.01583129782229662 and parameters: {'w1': 0.862517064679041, 'w2': 0.0805444171040643}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:09,046] Trial 375 finished with value: 0.015832205675542353 and parameters: {'w1': 0.8547711491221431, 'w2': 0.03485383581842108}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:09,297] Trial 376 finished with value: 0.015831344202160834 and parameters: {'w1': 0.8585009268514608, 'w2': 0.07104587896176778}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:09,594] Trial 377 finished with value: 0.01583190057426691 and parameters: {'w1': 0.8914746243506897, 'w2': 0.045077569381147965}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:09,898] Trial 378 finished with value: 0.015831893123686314 and parameters: {'w1': 0.8638564958229406, 'w2': 0.1254200305514151}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:10,121] Trial 379 finished with value: 0.015831391140818597 and parameters: {'w1': 0.8939521641374332, 'w2': 0.1027973679385008}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:10,344] Trial 380 finished with value: 0.015831299312412738 and parameters: {'w1': 0.8802800423950178, 'w2': 0.08617713627307261}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:10,566] Trial 381 finished with value: 0.015831452421844007 and parameters: {'w1': 0.8492377572426173, 'w2': 0.06143719414573301}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:10,783] Trial 382 finished with value: 0.015836193412542342 and parameters: {'w1': 0.8794432541983227, 'w2': 0.2206305774568782}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:11,000] Trial 383 finished with value: 0.01583130471408367 and parameters: {'w1': 0.880670343236015, 'w2': 0.08000671988132962}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:11,220] Trial 384 finished with value: 0.015831471420824528 and parameters: {'w1': 0.8543453131906062, 'w2': 0.10437842271028722}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:11,433] Trial 385 finished with value: 0.015833207219839097 and parameters: {'w1': 0.8423147030074023, 'w2': 0.015082355866373326}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:11,656] Trial 386 finished with value: 0.015831951610744 and parameters: {'w1': 0.8681529645844843, 'w2': 0.04233176651193484}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:11,879] Trial 387 finished with value: 0.01583140455186367 and parameters: {'w1': 0.9229358973450641, 'w2': 0.07030377929401396}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:12,094] Trial 388 finished with value: 0.015831942297518255 and parameters: {'w1': 0.8929917125399236, 'w2': 0.13147161056608797}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:12,312] Trial 389 finished with value: 0.015831315144896507 and parameters: {'w1': 0.8337086830218146, 'w2': 0.08705689403300804}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:12,525] Trial 390 finished with value: 0.015831631794571876 and parameters: {'w1': 0.8620821774901739, 'w2': 0.053201434269436604}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:12,736] Trial 391 finished with value: 0.015831565484404564 and parameters: {'w1': 0.8513085910826226, 'w2': 0.10930131355389451}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:12,950] Trial 392 finished with value: 0.015832593478262425 and parameters: {'w1': 0.8758607212047744, 'w2': 0.0269376808426358}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:13,170] Trial 393 finished with value: 0.015831414982676505 and parameters: {'w1': 0.9054434869848423, 'w2': 0.06812070215339504}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:13,392] Trial 394 finished with value: 0.01583132930099964 and parameters: {'w1': 0.8317869483234145, 'w2': 0.08905901992165463}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:13,611] Trial 395 finished with value: 0.0158315297216177 and parameters: {'w1': 0.3854465444288673, 'w2': 0.04862683516540562}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:13,825] Trial 396 finished with value: 0.01583408247679472 and parameters: {'w1': 0.9435977130320564, 'w2': 0.0029798303716971897}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:14,037] Trial 397 finished with value: 0.015832635387778283 and parameters: {'w1': 0.8749346317462824, 'w2': 0.1501506464598369}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:14,246] Trial 398 finished with value: 0.015831366740167142 and parameters: {'w1': 0.8969628470377617, 'w2': 0.07154878764694536}. Best is trial 229 with value: 0.01583129558712244.\n[I 2020-10-01 05:29:14,453] Trial 399 finished with value: 0.015831500105559827 and parameters: {'w1': 0.8482230059201233, 'w2': 0.10532270425406068}. Best is trial 229 with value: 0.01583129558712244.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"best_trial:\")\nbest_trial = study.best_trial\nbest_trial.params","execution_count":392,"outputs":[{"output_type":"stream","text":"best_trial:\n","name":"stdout"},{"output_type":"execute_result","execution_count":392,"data":{"text/plain":"{'w1': 0.7294536413552165, 'w2': 0.06924639830655917}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"noice_weights = np.array([\n    best_trial.params[\"w1\"], \n    best_trial.params[\"w2\"]\n])\n\n\nbb = blend(\n    weights = noice_weights, \n    model_list = [Model(), Model_2()],\n    model_filenames = model_filenames\n)","execution_count":393,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss_op = validate_fn(bb, val_loader, criterion, device)\ntest_val_losses[\"blend_with_optuna\"] = val_loss_op\ntest_val_losses","execution_count":394,"outputs":[{"output_type":"execute_result","execution_count":394,"data":{"text/plain":"{'model_1': 0.015834295190870762,\n 'model_2': 0.01613880954682827,\n 'model_blend': 0.01589357666671276,\n 'blend_with_optuna': 0.01583129558712244}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'font.size': 15})\n\nnames = test_val_losses.keys()\nvals = test_val_losses.values()\n\nbars = plt.bar(names, vals)\nbars[0].set_color(\"purple\")\nbars[1].set_color(\"purple\")\nbars[-1].set_color(\"g\")\nplt.ylim(min(vals)- .00005, max(vals) + 0.00005)\nplt.ylabel(\"loss on validation set\", fontsize = 18)\nplt.xlabel(\"models ->\", fontsize = 15)\nplt.axhline(y = min(vals), linestyle = \"--\", c = \"r\", linewidth = 5)\nplt.title(\"loss drop with optuna <-ve is good> = \" + str(test_val_losses[\"blend_with_optuna\"] - test_val_losses[\"model_blend\"]) + \"  Best loss: \" + str(test_val_losses[\"blend_with_optuna\"]))\nplt.show()","execution_count":395,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1080x504 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}