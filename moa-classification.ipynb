{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom sklearn.preprocessing import MinMaxScaler\n\n        \n        \nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.dataset import random_split","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/lish-moa/test_features.csv\n/kaggle/input/lish-moa/sample_submission.csv\n/kaggle/input/lish-moa/train_features.csv\n/kaggle/input/lish-moa/train_targets_scored.csv\n/kaggle/input/lish-moa/train_targets_nonscored.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\nsubmission = pd.read_csv('../input/lish-moa/sample_submission.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_categorical(category, df):\n    s = str(category)\n    df = pd.get_dummies(df, columns=[s])\n    return df\n\ndef encode_df(df):\n    \n    df_encoded = convert_categorical('cp_type', df)\n    df_encoded1 = convert_categorical('cp_dose', df_encoded)\n    return(df_encoded1)\n\ntrain_features_encoded = encode_df(train_features)\n\nif 'cp_dose_D1'and'cp_type_trt_cp' in train_features_encoded.columns:\n    print(\"encoded columns successfully\")\nelse:\n    print(\"Nope\")","execution_count":5,"outputs":[{"output_type":"stream","text":"encoded columns successfully\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_encoded.shape, train_targets_scored.shape\n","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"((23814, 878), (23814, 207))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns = train_features_encoded.columns[1:]\ntarget_columns = train_targets_scored.columns[1:]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cat = train_features_encoded.merge(train_targets_scored, on='sig_id')\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_df = train_cat.loc[:, train_cat.columns != 'sig_id']\ndf_float = dummy_df.astype(float)\nscaler = MinMaxScaler()\ndf_float_scaled = pd.DataFrame(scaler.fit_transform(df_float), columns = df_float.columns)\ndf_float_scaled['sig_id'] = train_features_encoded['sig_id']\ndf_float_scaled.info()\n","execution_count":9,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df_encoded' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-64884febf3df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_float_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_float\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_float_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sig_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sig_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf_float_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df_encoded' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df, feature_columns, target_columns):\n        \n        self.features  = df[feature_columns].values\n        self.targets = df[target_columns].values\n        \n    def __len__(self):\n        return self.features.shape[0]\n\n    def __getitem__(self, idx):\n        feature = torch.tensor(self.features[idx])\n        target = torch.tensor(self.target[idx])\n        \n        return feature,target","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_dataset = TrainDataset(df_float_scaled, feature_columns, target_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = int(0.9 * len(full_dataset))  ## 90/10 split\ntest_size = len(full_dataset) - train_size\ntrain_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers = 8)\n\nval_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle = True, num_workers = 8)\n\nprint(len(train_loader), \"batches \")\nprint(len(val_loader), \" batches \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n\n        self.dropout = nn.Dropout(p=0.2)\n        self.fc1 = nn.Linear(5, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 128)\n        self.fc4 = nn.Linear(128, 128)\n\n        self.fc5 = nn.Linear(128, 64)\n        self.fc6 = nn.Linear(64, 32)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.dropout(F.relu(self.fc3(x)))\n        x = self.dropout(F.relu(self.fc4(x)))\n\n        x = F.relu(self.fc5(x))\n\n        return (self.fc6(x))\n    \nmodel = Model()\nprint(model)\nmodel = model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}