{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport time\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom sklearn.preprocessing import MinMaxScaler\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.dataset import random_split\n\n\nfrom IPython.display import clear_output\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage.filters import gaussian_filter1d   ## smoother\nfrom tqdm.notebook import tqdm\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau","execution_count":50,"outputs":[{"output_type":"stream","text":"/kaggle/input/lish-moa/test_features.csv\n/kaggle/input/lish-moa/sample_submission.csv\n/kaggle/input/lish-moa/train_features.csv\n/kaggle/input/lish-moa/train_targets_scored.csv\n/kaggle/input/lish-moa/train_targets_nonscored.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"if torch.cuda.is_available():\n    device='cuda'\nelse:\n    device='cpu'\n    \ndevice","execution_count":51,"outputs":[{"output_type":"execute_result","execution_count":51,"data":{"text/plain":"'cuda'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\nsubmission = pd.read_csv('../input/lish-moa/sample_submission.csv')","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pre_process_data(train_features, train_targets_scored):\n    \n    feature_columns = list(train_features.columns[1:])\n    target_columns = list(train_targets_scored.columns[1:])\n    \n    removal_list = ['cp_type', 'cp_dose']\n    for x in removal_list:\n        feature_columns.remove(x)\n        \n    train_cat = train_features.merge(train_targets_scored, on='sig_id')\n    train_cat = train_cat.select_dtypes(exclude=['object'])\n    \n    dummy_df = train_cat.loc[:, train_cat.columns != 'sig_id']\n    df_float = dummy_df.astype(float)\n    scaler = MinMaxScaler()\n    df_float_scaled = pd.DataFrame(scaler.fit_transform(df_float), columns = df_float.columns)\n    df_float_scaled['sig_id'] = train_features['sig_id']\n    return(df_float_scaled)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_float_scaled = pre_process_data(train_features, train_targets_scored)\nfeature_columns = list(train_features.columns[1:])\nremoval_list = ['cp_type', 'cp_dose']\nfor x in removal_list:\n    feature_columns.remove(x)\ntarget_columns = list(train_targets_scored.columns[1:])","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df, feature_columns, target_columns):\n        \n        self.features  = df[feature_columns].values\n        self.targets = df[target_columns].values\n        \n    def sizes(self):\n        print(\"features size = \", self.features.shape[1])\n        print(\"targets size = \", self.targets.shape[1])\n\n        \n    def __len__(self):\n        return self.features.shape[0]\n\n    def __getitem__(self, idx):\n        feature = torch.tensor(self.features[idx]).float()\n        target = torch.tensor(self.targets[idx]).float()\n        \n        return feature,target","execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_dataset = TrainDataset(df_float_scaled, feature_columns, target_columns)","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = int(0.9 * len(full_dataset))  ## 90/10 split\ntest_size = len(full_dataset) - train_size\ntrain_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers = 8)\n\nval_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle = True, num_workers = 8)\n\nprint(len(train_loader), \"batches \")\nprint(len(val_loader), \" batches \")","execution_count":57,"outputs":[{"output_type":"stream","text":"335 batches \n38  batches \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n        \ndef show_lr(learning_rates):\n    plt.plot(learning_rates, label = \"learning rate\")\n    plt.ylabel(\"Learning rate\", fontsize = 15)\n    plt.grid(True)\n    plt.legend()\n    plt.show()\n    \ndef show_deltas(deltas):\n    deltas = gaussian_filter1d(deltas, sigma=3)\n    plt.plot(deltas, \"r\", label = \"Absolute error from label \")\n    plt.ylabel(\"Error\", fontsize = 15)\n    plt.grid(True)\n    plt.legend()\n    plt.show()\n    \ndef show_losses(loss_list):\n    plt.plot(loss_list, 'r', label = 'Loss')\n    plt.ylabel(\"Loss\", fontsize = 15)\n    plt.grid(True)\n    plt.legend()\n    plt.show()\n    \ndef train_step(x, y, model, optimizer, criterion):\n        optimizer.zero_grad()\n        pred = model(x.to(device))\n        y = y.float()\n        loss = criterion(pred,y.to(device))\n        loss.backward()\n        optimizer.step()\n        return loss.item()","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.batch_norm1 = nn.BatchNorm1d(873)\n        self.dropout1 = nn.Dropout(0.2)\n        self.dense1 = nn.utils.weight_norm(nn.Linear(873, 2048))\n        \n        self.batch_norm2 = nn.BatchNorm1d(2048)\n        self.dropout2 = nn.Dropout(0.5)\n        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1048))\n        \n        self.batch_norm3 = nn.BatchNorm1d(1048)\n        self.dropout3 = nn.Dropout(0.5)\n        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, 206))\n    \n    def forward(self, x):\n        x = self.batch_norm1(x)\n        x = self.dropout1(x)\n        x = F.relu(self.dense1(x))\n        \n        x = self.batch_norm2(x)\n        x = self.dropout2(x)\n        x = F.relu(self.dense2(x))\n        \n        x = self.batch_norm3(x)\n        x = self.dropout3(x)\n        x = (self.dense3(x))\n        \n        return x\n    \n    \nmodel = Model()\nprint(model)\nmodel = model.to(device)","execution_count":59,"outputs":[{"output_type":"stream","text":"Model(\n  (batch_norm1): BatchNorm1d(873, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout1): Dropout(p=0.2, inplace=False)\n  (dense1): Linear(in_features=873, out_features=2048, bias=True)\n  (batch_norm2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout2): Dropout(p=0.5, inplace=False)\n  (dense2): Linear(in_features=2048, out_features=1048, bias=True)\n  (batch_norm3): BatchNorm1d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout3): Dropout(p=0.5, inplace=False)\n  (dense3): Linear(in_features=1048, out_features=206, bias=True)\n)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = []\nval_losses = []\nlearning_rates = []\naverage_deltas = []\nval_corr=[]\n\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                 mode='min', \n                                                 factor=0.1, \n                                                 patience=3, \n                                                 eps=1e-4, \n                                                 verbose=True)\ncriterion = nn.BCEWithLogitsLoss()","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs=15\nfor epoch in range(num_epochs):\n    \n    clear_output(wait = True)\n    show_lr(learning_rates)\n    #show_deltas(average_deltas)\n    show_losses(val_losses)\n    \n    total_loss = 0\n    total_correct = 0\n    total_loss2 = 0\n    total_correct2 = 0\n    \n    print (\"epoch \", epoch+1, \" out of \", num_epochs )\n\n    \n    with torch.no_grad():\n        model.eval()\n\n        for x_val, y_val in tqdm(val_loader, desc = \"running on test set --\"):\n            yhat =model(x_val.to(device))  # pred \n            #yhat = torch.round(torch.sigmoid(yhat))\n            val_loss = criterion(yhat.to(device), y_val.to(device))\n            val_losses.append(val_loss.item())  ## metrics \n            #average_deltas.append(torch.mean(torch.abs(yhat.cpu()-y_val.cpu())).item())\n\n\n    model.train()\n    for batch in tqdm(train_loader, desc = \" Training batches : \"):\n        (x_batch, y_batch) = batch\n        loss = train_step(x_batch.to(device), y_batch.to(device), model, optimizer, criterion)\n        losses.append(loss)\n    scheduler.step(1.)   ## lr decay caller \n    learning_rates.append(get_lr(optimizer))\n\n    clear_output(wait = True)\n\n    show_lr(learning_rates)\n    show_losses(val_losses)\n    #show_deltas(average_deltas)","execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5zUZd3/8dfH5aSCaCiLsSgYlFEi6N4c8sCah0AssrToNjV/eXNT0UEzw5/lrXnXz1O/2xuliMyyrChNb8lQU2PE8hBaaCyIrucVjyjgQhx293P/cc26szOzy+7w3S87F+/n4/F97HyPc31mZuc91/Wdg7k7IiIiuXbb2Q0QEZGeR+EgIiIFFA4iIlJA4SAiIgUUDiIiUqDXzm5AEvbdd18fPnx4Sftu3LiRPffcM9kG9QAx1hVjTRBnXTHWBPHV9eijj77h7vsVWxdFOAwfPpxHHnmkpH0zmQw1NTXJNqgHiLGuGGuCOOuKsSaIry4ze769dRpWEhGRAgoHEREpoHAQEZECqZ9zMLMpwH8DFcB17n5Z3vpvAKdlZ3sB7wf2c/c3U22oiOwStm3bRn19PZs3b97utgMHDmTVqlUptCpZ/fr1o6qqit69e3d6n1TDwcwqgHnA8UA9sMzMFrn7ypZt3P1K4Mrs9h8FzlEwiEh3qa+vZ8CAAQwfPhwz63Dbt99+mwEDBqTUsmS4O2vXrqW+vp4RI0Z0er+0h5XGA3Xu/oy7bwUWAtM72P4zwK9TaZmI7JI2b97MoEGDthsM5crMGDRoUKd6Rm32S/NbWc3sFGCKu5+dnT8dmODus4tsuwehdzGyWM/BzGYCMwEqKysPX7hwYUltamhooH///iXt25PFWFeMNUGcdZVTTQMHDmTkyJGd2rapqYmKiopublH3qKurY/369W2WHXPMMY+6e3Wx7dM+51AsmttLp48Cf2lvSMndFwALAKqrq72k9x7X1vLcT3/KOx+gM4Pddgt/W6+ocL/8VxjuYWpuhg9+EE49tettSVhs78eGOGuCOOsqp5pWrVrV6aGichxWatGvXz/GjRvX6e3TDod6YFjOfBWwpp1tZ9DdQ0orVzL85z9P9pj9+/eIcBCR8tG/f38aGhp2djPaSPucwzJglJmNMLM+hABYlL+RmQ0EJgO3dWtrTj2VzJIlbV/5NzXBtm3Q2Ng6NTW1Ti3L8rdpboZvfCNcFhEpc6mGg7s3ArOBu4BVwG/dvdbMZpnZrJxNTwb+6O4b02zfO8NKvXpBRUXrtNturVPLsvxtIj2ZJSI7x/Lly5k4cSJjxozh5JNP5q233gJg7ty5jB49mjFjxjBjxgwA7rvvPsaOHcvYsWMZN24cb7/99g5ff+qfc3D3xcDivGXz8+Z/BvwsvVYlxKz4OQoRKQ9f+xosX97u6t2bmsKLwa4YOxauvrrLTTnjjDO45pprmDx5MhdddBGXXHIJV199NZdddhnPPvssffv2Zd26dQBcddVVzJs3jyOOOIKGhgb69evX5evLp09IJ0nhICIJWL9+PevWrWPy5MkAnHnmmSxduhSAMWPGcNppp3HjjTfSq1d4fX/EEUdw7rnnMnfuXNatW/fO8h0Rxbey9igKB5HytZ1X+P/sAe9W+sMf/sDSpUtZtGgRl156KbW1tcyZM4dp06axePFiJk6cyD333MPBBx+8Q9ejnkOSdN5BRBIwcOBA9tlnH+6//34AfvGLXzB58mSam5t58cUXOeaYY7jiiitYt24dDQ0NPP300xxyyCF885vfpLq6mieeeGKH26CeQ5I0rCQiJdi0aRNVVVXvzJ977rnccMMNzJo1i02bNnHQQQfx05/+lKamJj772c+yfv163J1zzjmHvffem29/+9ssWbKEiooKRo8ezdSpU3e4TQqHpCkcRKSLmpubiy5/6KGHCpb9+c9/Llh2zTXXJN4mDSslScNKIhIJhUOSNKwkIpFQOCRJ4SBSltL8AtKdoZT6FA5Ji/xBJhKbfv36sXbt2mgDouX3HLr6wTidkE6SzjmIlJ2qqirq6+t5/fXXt7vt5s2bE/n0cdpafgmuKxQOSVI4iJSd3r17d/oX0jKZTJe+9rqcaVipO0TaPRWRXYfCIUnqOYhIJBQOSWoJB/UcRKTMKRySpHAQkUgoHEREpIDCIUnqOYhIJBQOSVI4iEgkFA7dQeEgImVO4ZAkvZVVRCKRejiY2RQzW21mdWY2p51tasxsuZnVmtl9abexZBpWEpFIpPr1GWZWAcwDjgfqgWVmtsjdV+ZsszfwA2CKu79gZoPTbOMOUTiISCTS7jmMB+rc/Rl33wosBKbnbfOvwC3u/gKAu7+WchtFRHZ5aX/x3lDgxZz5emBC3jbvBXqbWQYYAPy3u/88/0BmNhOYCVBZWUkmkympQQ0NDSXvm++AZ5/lIGDpfffR3LdvIscsVZJ19RQx1gRx1hVjTRBvXcWkHQ7Fztjmj8H0Ag4HjgV2Bx40s4fc/ck2O7kvABYAVFdXe01NTUkNymQylLpvgYcfBuDoo46CPfZI5pglSrSuHiLGmiDOumKsCeKtq5i0w6EeGJYzXwWsKbLNG+6+EdhoZkuBQ4EnKRc65yAiZS7tcw7LgFFmNsLM+gAzgEV529wGHGVmvcxsD8Kw06qU21kavZVVRCKRas/B3RvNbDZwF1ABXO/utWY2K7t+vruvMrM7gceBZuA6d1+RZjtLpncriUgkUv8lOHdfDCzOWzY/b/5K4Mo025UIhYOIREKfkBYRkQIKhySp5yAikVA4JEnhICKRUDiIiEgBhUOS1HMQkUgoHJKkcBCRSCgcuoPCQUTKnMIhSfqEtIhEQuGQJA0riUgkFA5JUjiISCQUDiIiUkDhkCT1HEQkEgqHJCkcRCQSCofuoHAQkTKncEiS3soqIpFQOCRJw0oiEgmFQ5IUDiISCYWDiIgUUDgkST0HEYmEwiFJCgcRiUTq4WBmU8xstZnVmdmcIutrzGy9mS3PThel3cYdpnAQkTLXK80rM7MKYB5wPFAPLDOzRe6+Mm/T+939pDTblgi9lVVEIpF2z2E8UOfuz7j7VmAhMD3lNnQfDSuJSCRS7TkAQ4EXc+brgQlFtptkZo8Ba4Dz3L02fwMzmwnMBKisrCSTyZTUoIaGhpL3zTdk9WoOBh584AG2VFYmcsxSJVlXTxFjTRBnXTHWBPHWVUza4VBs3CX/ZfbfgAPdvcHMTgT+BxhVsJP7AmABQHV1tdfU1JTUoEwmQ6n7Fnj6aQAmTZoEBxyQzDFLlGhdPUSMNUGcdcVYE8RbVzFpDyvVA8Ny5qsIvYN3uPsGd2/IXl4M9DazfdNr4g7QsJKIRCLtcFgGjDKzEWbWB5gBLMrdwMyGmIVnWTMbn23j2pTbWRqFg4hEItVhJXdvNLPZwF1ABXC9u9ea2azs+vnAKcAXzKwR+Ccww13PtiIiaUr7nEPLUNHivGXzcy5fC1ybdrsSoZ6DiERCn5BOksJBRCKhcEiSwkFEIqFwEBGRAgqHJKnnICKRUDgkSeEgIpFQOIiISAGFQ5LUcxCRSCgckqRwEJFIKBy6g8JBRMqcwiFJ+rEfEYmEwiFJGlYSkUgoHJKkcBCRSCgcRESkgMIhSeo5iEgkFA5JUjiISCQUDiIiUkDhkCT1HEQkEgqHJCkcRCQSCockKRxEJBIKBxERKZB6OJjZFDNbbWZ1Zjang+3+xcyazOyUNNu3Q9RzEJFIpBoOZlYBzAOmAqOBz5jZ6Ha2uxy4K8327TCFg4hEIu2ew3igzt2fcfetwEJgepHtvgz8DngtzcaJiEjQK+XrGwq8mDNfD0zI3cDMhgInAx8G/qW9A5nZTGAmQGVlJZlMpqQGNTQ0lLxvvkErVnAI8MiyZTSsX5/IMUuVZF09RYw1QZx1xVgTxFtXMTscDmZ2MHAw8Fd3X7O9zYssyx+DuRr4prs3WQdfge3uC4AFANXV1V5TU9PpNufKZDKUum+BDRsAqD78cDj88GSOWaJE6+ohYqwJ4qwrxpog3rqK6VI4mNmPAHf3Wdn5TwM3AhVAg5lNcfcHOjhEPTAsZ74KyA+UamBhNhj2BU40s0Z3/5+utHWn0DkHEYlEV885TAGW5sxfCvwaeDfh5PGl29l/GTDKzEaYWR9gBrAodwN3H+Huw919OHAz8MWyCAYRkYh0dVhpMNlzBmY2ChgJfMLdXzGzBcBvOtrZ3RvNbDYhSCqA69291sxmZdfP72oBPYp6DiISia6Gw5tAZfbyccAr7r4iO2+EJ/wOuftiYHHesqKh4O6f62L7di6Fg4hEoqvhcAfwHTOrBM4Hfpuz7oPAcwm1S0REdqKunnP4OvAQMItw7uGinHUnA3cm1K7ypJ6DiESiSz0Hd18P/J921h2VSIvKmcJBRCLR1bey9gIq3H1LzrITCF+FcZ+7/z3h9pUXhYOIRKKr5xx+A7zTezCzrxA+tLYFqDCzT7j77ck2UURE0tbVcw4TaftOo28A33f33YHrgAuTalhZUs9BRCLR1XAYBLwCYGaHED781vI21JsIw0u7LoWDiESiq+HwKjA8e3kK8Ly7P52d3x1oTqhdIiKyE3X1nMNNwOVmdihwFnBtzrpxwFNJNawsqecgIpHoajjMATYQvkr7h8D/y1l3ONv5+ozoKRxEJBJd/ZxDI/CddtZ9IpEWlbMOvmJcRKSclPR7DmY2ATgSeBfh+5b+7O4PJ9mwsqaeg4iUua5+CG5PwnmHKUAjsJbwDqYKM7sTONXdNyXeynKhYSURiURX3610BTAJ+DTQz933B/oRfpdhEnB5ss0rMwoHEYlEV8Phk4Sf8LzJ3ZsB3L3Z3W8inKw+NekGiohI+roaDgPJ/thPES8Ce+1Yc8qceg4iEomuhsNjwBfM2r4tJzv/hez6XZfCQUQi0dV3K/1fwg/+PGFmtxI+MT2Y8FsOw4GpibZORER2iq5+zuFPZjaO8CM/pwL7Ay8DDwMzk29emVHPQUQi0eXPObj7SsK7k9ows08SfjZ0u78jHS2Fg4hEoqvnHHaYmU0xs9VmVmdmc4qsn25mj5vZcjN7xMyOTLuNJVM4iEgkSvqEdKnMrAKYBxwP1APLzGxRtjfS4l5gkbu7mY0h9EYOTrOdIiK7urR7DuOBOnd/xt23AguB6bkbuHuD+zsvvfcEyudluHoOIhKJVHsOwFDafk6iHpiQv5GZnUz4xtfBwLRiBzKzmWRPgldWVpLJZEpqUENDQ8n75ttrxQoOAx5bvpy3+vRJ5JilSrKuniLGmiDOumKsCeKtq5jthoOZvU7nXr337cQ2xb62tODY7n4rcKuZHQ1cChxXZJsFwAKA6upqr6mp6cTVF8pkMpS6b4FsIBx66KGQ1DFLlGhdPUSMNUGcdcVYE8RbVzGd6TnMI7mhnXpgWM58FbCmvY3dfamZvcfM9nX3NxJqQ/fRsJKIRGK74eDuFyd4fcuAUWY2AniJ8JbYf83dwMxGAk9nT0gfBvQhfPtrz6dwEJFIpHrOwd0bzWw2cBfh8xDXu3utmc3Krp9P+HK/M8xsG/BP4NM5J6h7Nv3Yj4hEIu0T0rj7YmBx3rL5OZcvp9y/+rtMskxEpD2pfwguahpWEpFIKBySpHAQkUgoHEREpIDCIUnqOYhIJBQOSVI4iEgkFA5J0ltZRSQSCofuoJ6DiJQ5hUOSNKwkIpFQOCRJ4SAikVA4iIhIAYVDktRzEJFIKBySpHAQkUgoHJKkt7KKSCQUDt1BPQcRKXMKhyRpWElEIqFwSJLCQUQioXAQEZECCockqecgIpFQOCRJ4SAikVA4iIhIgdTDwcymmNlqM6szszlF1p9mZo9npwfM7NC021gy9RxEJBKphoOZVQDzgKnAaOAzZjY6b7NngcnuPga4FFiQZht3iMJBRCKRds9hPFDn7s+4+1ZgITA9dwN3f8Dd38rOPgRUpdzG0ukT0iISiV4pX99Q4MWc+XpgQgfbfx64o9gKM5sJzASorKwkk8mU1KCGhoaS9823+4svMgFYWVvLawkds1RJ1tVTxFgTxFlXjDVBvHUVk3Y4FHtpXXQMxsyOIYTDkcXWu/sCskNO1dXVXlNTU1KDMpkMpe5b4KmnABj9/vczOqljlijRunqIGGuCOOuKsSaIt65i0g6HemBYznwVsCZ/IzMbA1wHTHX3tSm1bcfpnIOIRCLtcw7LgFFmNsLM+gAzgEW5G5jZAcAtwOnu/mTK7RMREVLuObh7o5nNBu4CKoDr3b3WzGZl188HLgIGAT+w8Eq80d2r02xnydRzEJFIpD2shLsvBhbnLZufc/ls4Oy025UIhYOIREKfkE6S3soqIpFQOHQH9RxEpMwpHJKkYSURiYTCIUkKBxGJhMJBREQKKBySpJ6DiERC4ZAkhYOIRELhkCS9lVVEIqFw6A7qOYhImVM4JEnDSiISCYVDkjSsJCKRUDh0B/UcRKTMKRySpGElEYmEwiFJCgcRiYTCIUk65yAikVA4dAf1HESkzCkckqRhJRGJhMIhSRpWEpFIKBy6g3oOIlLmFA5J0rCSiEQi9XAwsylmttrM6sxsTpH1B5vZg2a2xczOS7t9O0ThICKR6JXmlZlZBTAPOB6oB5aZ2SJ3X5mz2ZvAV4CPp9m2ROicg4hEIu2ew3igzt2fcfetwEJgeu4G7v6auy8DtqXctuSo5yAiZS7VngMwFHgxZ74emFDKgcxsJjAToLKykkwmU1KDGhoaSt43X6+33+ZIoO6pp6hP6JilSrKuniLGmiDOumKsCeKtq5i0w6HYuEtJL7PdfQGwAKC6utprampKalAmk6HUfQusWwfAyJEjGZnUMUuUaF09RIw1QZx1xVgTxFtXMWkPK9UDw3Lmq4A1Kbeh+2lYSUTKXNrhsAwYZWYjzKwPMANYlHIbuo/erSQikUh1WMndG81sNnAXUAFc7+61ZjYru36+mQ0BHgH2AprN7GvAaHffkGZbS6JwEJFIpH3OAXdfDCzOWzY/5/IrhOEmERHZSfQJ6SSp5yAikVA4JEnhICKRUDgkSZ+QFpFIKBy6g3oOIlLmFA5J0rCSiERC4ZAkDSuJSCQUDt1BPQcRKXMKhyRpWElEIqFwSJLCQUQioXBIks45iEgkFA7dQT0HESlzCockaVhJRCKhcEiShpVEJBIKh+6gnoOIlDmFQ5Jaeg5NTfDSS/DVr0JDQ+v6xx6DjRtb593h4YehsbF1WXNz8WO/+Sb8/e/Jt3lHtdfeznj9dXj88eTaEqv162FDz/85E4mLwiFJLeFwySVQVQVz58KAAfCRj8CnPgVjx0L//mG73XaDAw6AiRPh4IPhwAPD8t694cMfhssvh4ULw77PPw8nngiHHQYLFsCWLW2vN7+nsno1e61YAc89B3/6E2zbFpYvWhSWQeuyfM8+C2vXbr9Wd3j1VaiogOuv7+wt1NbUqXDoobBpU+G6v/4Vbr65tOO2tG/hQnjttdKPUeyYDQ0h1Lq6X21t6df7rnfB8OGl79+e5mZYurT0nm5jY9sXNjuqsRFefjm543XWxo2walWyx7zkkvD4LkV9fee3Peec8H/dHdy97KfDDz/cS7VkyZKS9y3q4x93D/9urdPgwe6DBhUub5mqqlovjx0bptz1H/pQ2/lPf9r9S19yv/FG92OPdR8yxP34492HDXMfPrzw+F//uvvvfx8uDxkS9u/d2/3BB1vbvXGje3V12OZ973Nvbna/+273q65yf/1198ZG9zvucJ8wIbR31Ki29W3eHPb57W9D+59/3n3VqtCeL3yh9XrmzXP/2c/cb7ihdf9bbnF/+eXQBnf3rVtb140a5b5pU+t91dzsfu+97mee6X7XXe5NTe5PPOG+dm3b++HPfw77n3hiON63vuV+/fVhXXOz+803u7/5Ztj/pZda93v99dB2d/d//tN9yRL3p592z2Tc+/VrbVeLW28NdS5e7H777eF427aFdZs2hev62c/CPrfdFo6ZZ8mSJeH2feMN91deCcdobg4r584tvM58TU2t1/fyy+7r1rVd39DgvmFDOOYLL7Re11lnheP+5CfhsdRy++S68073RYvc16wJj5ebbw7HcHc/7DD3I48s2qT7b7vN/YILwn26fn3blVu3ui9d2nbZxo3un/xkaM8f/xgeg88+G/Z9+eXCK2hsdP/lL8M2r7zivnKl+5Yt4e+rr7Z/W7mH/6eTTmqdnzIlXG9DQ/v7NDW519WF+yr/Pty4Mdw2zc1hevLJ1vus5bZqafO994a/7uFx8rvfhdu2xR13hP1uvbV12UMPtd4GTU3h9tu61f2tt8K23/1ux/V2AHjE23le3elP7ElMPSocmprCE0z+A6ixMTx4V68Od/yjj7pfdlm4g93DE0zuPkuWuP/61+6HHNJ+qCQxHXqo+7Rphcv337/18tSp7jU1HR+nb9+O1w8e3P66Xr3cd989BOj48cXbMmCAbxoyxP2EE9qua3nC3m0397q68M954YVhvth1PfWU+3vf6++E4Je+FC5PmBCeaPbYI8z/8IchSNtr88iR7h/7WOHy4cNDe489tv1aL77YvbY2BNzRR/tL06a5jxtXuO3AgW3nP/IR9wULwhP0AQeEZdOmhTbX1LRuv8ceIawmTXK/557CFyYXX+z+7ncXb9+gQeF2ufhi99NOa11u1na7SZNaL592mvvRR4cXExde6H7GGYXHfd/73E8/3f2669xnzAjLzjsvbHvqqW1fILVMp5wSwgdC3bNnh32fe879i1/s+PF24onuJ58c/seuvDJcx+c+1xoEEF7E7LNP6/y++4bjvuc94Xpvu839scfCk282uF445ZTwwuqqq0KgPv+8+3HHhf2PP77wxeG//7v7ffeF26flf/nss0Obcrf7wQ/CC7iWF2jgftBB7mPGtM5fdll4DID7iBHhhRaEMC2RwqEDiYdD0mprw6vxyy8Pr7bvuis8CL/ylXD3nX++e329+xVXuP/nf4Ynpvvu87dHjHC/9trwimbAgNYH4NVXh+Wnn174D/WpT7n/6EchDIYNc//sZ90vvdTfefL/r/8KryQnTQrr/vGP8I+Te4y99269/LGPuf/hD4XBMXFi6+WWHkhFRXjir6kJTwq77966zV57dfxEUGz61Kfcf/zjru+XOx1wQLjNWuYnTAj/sLnb7Lmn+4EHuk+f3vGxRo4sfILNn/r3L72tLfdxT5zOOy/U39769oK8M1Nuby7/tsx9LHZlOvLI1vAtNhW7H9/znsJlJ53Uerl37+67fd98s+Snl47CwcL68lZdXe2PPPJISftmMhlqamqSbVBa1q2DvfcuuqpNXe6Fb7N1h7q6cKIbYMgQGDYsnAvJ1dgI3/lOGD+dNKnwihob4ZOfhJkzYdq0cNyXXgrrqrI/Bb56NfTtG8aThwyBESPCOG8mA8ceG07Kf+ADsO+++UXAhAnQrx9s2MAT3/seB592Wli3ZUsYx99rr3CsAQNg1izYbz+YPRvOOgv69IHly8PY+rBh8MAD8LvfhfXjx8OcOeHczpe/HG7H3/wm7HfCCTBwYDgP1KsX3HRT2H/ixHDdf/tbOGZTU2hfi1/9KtT6mc/AM8+Edn/rW3DnnaGdEM6vLF8Od9wRjr/HHtQ+9RQfGDcOPvpRePppeOEFOOoo+P3vYehQ+Mtf4OtfD+ejvvjFcIL6ggtC3a++Gmrp1Qs2bw51jB4Nu+8OF10EK1aENn7ve2Es+7vfDfU8/3w4V7TXXrBsWbgP//EPeP/74cknw34HHRTqOeyw8Dg5+mh45ZXWZU88Eeo580yYPBk+/nEYORKamljzH//BuydMCOuGDQttratrva3uuQfOOw9uuw2OOQbuvz9c99Ch8P3vh8sbNsDixfC5z8HgweH82UMPhfvwy1+GGTPCdhBuo7lz4dprw+13yCHhPly1Cs4/H1auhB//GO69N/wdOxauuSY8Lvv2Dee39twTTjopnAvcsgX+7d/g9tvDdpMnw5YtvDx7NvvPmQO33BLOiw0eHO63s88Ot8eNN8LnPx/u+379wvlDgJ/8JBxzv/3COauKirBvnz5w663h8bTPPqH+kSPhuutC/VdeGa7/3HNbb7sHHwznBU86CT70oVB7iczsUXevLrqyvdTorgmYAqwG6oA5RdYbMDe7/nHgsO0dM+qeQ4lirGu7NW3b1jpW3xktQ4A72S55XzU3u69Y0fUDt5w36eo+XXlcdGCn3FfNzeGcw89/7n7TTa3L7767dVi6RHTQc+hVcuSUwMwqgHnA8UA9sMzMFrn7ypzNpgKjstME4IfZvyId69XFh/NuuxX2ViQdZqG3WMp+w4Z1fZ9yZhZ63Kef3nb5ccd169Wm/VbW8UCduz/j7luBhcD0vG2mAz/PBttDwN5mtn/K7RQR2aWl2nMAhgIv5szXU9grKLbNUKDNG6DNbCYwE6CyspJMJlNSgxoaGkretyeLsa4Ya4I464qxJoi3rmLSDodi/bv8M+Kd2QZ3XwAsgHBCutSTymV9QroDMdYVY00QZ10x1gTx1lVM2sNK9UDugGEVsKaEbUREpBulHQ7LgFFmNsLM+gAzgPzPfi8CzrBgIrDe3XfCZ+pFRHZdqQ4ruXujmc0G7gIqgOvdvdbMZmXXzwcWAycS3sq6CTgrzTaKiEj65xxw98WEAMhdNj/nsgNfSrtdIiLSSt/KKiIiBaL4+gwzex14vsTd9wXeSLA5PUWMdcVYE8RZV4w1QXx1Heju+xVbEUU47Agze8Tb+26RMhZjXTHWBHHWFWNNEG9dxWhYSURECigcRESkgMIh+ynrCMVYV4w1QZx1xVgTxFtXgV3+nIOIiBRSz0FERAooHEREpMAuHQ5mNsXMVptZnZnN2dnt6Swzu97MXjOzFTnL3mVmd5vZU9m/++SsuyBb42oz+8jOafX2mdkwM1tiZqvMrNbMvppdXra1mVk/M/urmT2WremS7PKyramFmVWY2d/N7PbsfAw1PWdm/zCz5Wb2SHZZ2ddVkvZ+Ii72ifDdTk8DBwF9gMeA0Tu7XZ1s+9HAYcCKnGVXkP3ZVWAOcHn28uhsbX2BEdmaK3Z2De3UtT/Zn4UFBgBPZttftrURvoK+f/Zyb+BhYGI515RT27nAr4DbI3oMPpwFaxgAAAJGSURBVAfsm7es7OsqZdqVew6d+VW6HsndlwJv5i2eDtyQvXwD8PGc5QvdfYu7P0v4QsPxqTS0i9z9ZXf/W/by28Aqwg89lW1tHjRkZ3tnJ6eMawIwsypgGnBdzuKyrqkDsdbVoV05HNr7xblyVenZrzbP/h2cXV6WdZrZcGAc4ZV2WdeWHX5ZDrwG3O3uZV8TcDVwPtCcs6zca4IQ3H80s0ezvzYJcdTVZal/K2sP0qlfnItA2dVpZv2B3wFfc/cN1v4PxJdFbe7eBIw1s72BW83sgx1s3uNrMrOTgNfc/VEzq+nMLkWW9aiachzh7mvMbDBwt5k90cG25VRXl+3KPYfYfnHuVTPbHyD797Xs8rKq08x6E4Lhl+5+S3ZxFLW5+zogA0yhvGs6AviYmT1HGI79sJndSHnXBIC7r8n+fQ24lTBMVPZ1lWJXDofO/CpdOVkEnJm9fCZwW87yGWbW18xGAKOAv+6E9m2XhS7CT4BV7v7/c1aVbW1mtl+2x4CZ7Q4cBzxBGdfk7he4e5W7Dyf83/zJ3T9LGdcEYGZ7mtmAlsvACcAKyryuku3sM+I7cyL84tyThHcZXLiz29OFdv8aeBnYRnj18nlgEHAv8FT277tytr8wW+NqYOrObn8HdR1J6JY/DizPTieWc23AGODv2ZpWABdll5dtTXn11dD6bqWyronwzsXHslNty3NCuddV6qSvzxARkQK78rCSiIi0Q+EgIiIFFA4iIlJA4SAiIgUUDiIiUkDhICIiBRQOIiJS4H8BZCALtkrc4IUAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pre_process_data(test_features, submission )","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":63,"outputs":[{"output_type":"execute_result","execution_count":63,"data":{"text/plain":"   cp_time       g-0       g-1       g-2       g-3       g-4       g-5  \\\n0      0.0  0.311677  0.492348  0.425836  0.305543  0.564515  0.567412   \n1      1.0  0.335363  0.504033  0.538921  0.240668  0.426998  0.556299   \n2      0.0  0.359389  0.461120  0.433876  0.283037  0.349968  0.594606   \n3      0.0  0.378813  0.499827  0.484694  0.304352  0.411180  0.498574   \n4      0.5  0.321330  0.331182  0.585233  0.288463  0.411115  0.577218   \n\n        g-6       g-7       g-8  ...  trpv_agonist  trpv_antagonist  \\\n0  0.476241  0.765565  0.537236  ...           0.0              0.0   \n1  0.339822  0.780791  0.535747  ...           0.0              0.0   \n2  0.466018  0.719682  0.593902  ...           0.0              0.0   \n3  0.542799  0.731578  0.607347  ...           0.0              0.0   \n4  0.535683  0.800600  0.569840  ...           0.0              0.0   \n\n   tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n0                0.0                        0.0   \n1                0.0                        0.0   \n2                0.0                        0.0   \n3                0.0                        0.0   \n4                0.0                        0.0   \n\n   ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n0                                    0.0              0.0        0.0   \n1                                    0.0              0.0        0.0   \n2                                    0.0              0.0        0.0   \n3                                    0.0              0.0        0.0   \n4                                    0.0              0.0        0.0   \n\n   vitamin_d_receptor_agonist  wnt_inhibitor        sig_id  \n0                         0.0            0.0  id_0004d9e33  \n1                         0.0            0.0  id_001897cda  \n2                         0.0            0.0  id_002429b5b  \n3                         0.0            0.0  id_00276f245  \n4                         0.0            0.0  id_0027f1083  \n\n[5 rows x 1080 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cp_time</th>\n      <th>g-0</th>\n      <th>g-1</th>\n      <th>g-2</th>\n      <th>g-3</th>\n      <th>g-4</th>\n      <th>g-5</th>\n      <th>g-6</th>\n      <th>g-7</th>\n      <th>g-8</th>\n      <th>...</th>\n      <th>trpv_agonist</th>\n      <th>trpv_antagonist</th>\n      <th>tubulin_inhibitor</th>\n      <th>tyrosine_kinase_inhibitor</th>\n      <th>ubiquitin_specific_protease_inhibitor</th>\n      <th>vegfr_inhibitor</th>\n      <th>vitamin_b</th>\n      <th>vitamin_d_receptor_agonist</th>\n      <th>wnt_inhibitor</th>\n      <th>sig_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.311677</td>\n      <td>0.492348</td>\n      <td>0.425836</td>\n      <td>0.305543</td>\n      <td>0.564515</td>\n      <td>0.567412</td>\n      <td>0.476241</td>\n      <td>0.765565</td>\n      <td>0.537236</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>id_0004d9e33</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.335363</td>\n      <td>0.504033</td>\n      <td>0.538921</td>\n      <td>0.240668</td>\n      <td>0.426998</td>\n      <td>0.556299</td>\n      <td>0.339822</td>\n      <td>0.780791</td>\n      <td>0.535747</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>id_001897cda</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.359389</td>\n      <td>0.461120</td>\n      <td>0.433876</td>\n      <td>0.283037</td>\n      <td>0.349968</td>\n      <td>0.594606</td>\n      <td>0.466018</td>\n      <td>0.719682</td>\n      <td>0.593902</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>id_002429b5b</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.378813</td>\n      <td>0.499827</td>\n      <td>0.484694</td>\n      <td>0.304352</td>\n      <td>0.411180</td>\n      <td>0.498574</td>\n      <td>0.542799</td>\n      <td>0.731578</td>\n      <td>0.607347</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>id_00276f245</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>0.321330</td>\n      <td>0.331182</td>\n      <td>0.585233</td>\n      <td>0.288463</td>\n      <td>0.411115</td>\n      <td>0.577218</td>\n      <td>0.535683</td>\n      <td>0.800600</td>\n      <td>0.569840</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>id_0027f1083</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1080 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = TrainDataset(test_df, feature_columns, target_columns)","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False, num_workers = 8)","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_preds=[]\nwith torch.no_grad():\n    model.eval()\n    for x_test, y_test in tqdm(test_loader, desc = \"running on test set --\"):\n        pred =model(x_test.to(device, dtype=torch.float))  # pred \n        pred = pred.cpu()\n        pred = pred.sigmoid()\n        list_of_preds.append(list(pred[0].numpy()))","execution_count":66,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='running on test set --', max=3982.0, style=ProgressStyle(…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"858ebaad19dc42fbb6d490ddf4b949b3"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/lish-moa/sample_submission.csv')\nsub_cp = submission\nsub_cp.to_csv('./submission_cp.csv', index=None, header=True)","execution_count":67,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv \na = list_of_preds  \nwith open('./submission_cp.csv', \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerows(a)","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_sub = pd.read_csv('./submission_cp.csv', header = None)\nfinal_sub.head()","execution_count":69,"outputs":[{"output_type":"execute_result","execution_count":69,"data":{"text/plain":"        0          1         2         3         4         5         6    \\\n0 -6.906514 -10.037319 -7.067277 -5.738963 -4.801744 -7.583585 -6.978337   \n1 -7.721139 -10.020224 -6.574782 -6.825776 -4.716693 -6.878952 -6.121612   \n2 -8.474200 -12.549698 -7.744347 -6.534324 -5.394559 -8.327050 -7.023392   \n3 -7.345932 -10.993735 -7.128180 -6.974970 -5.456245 -7.196219 -7.282748   \n4 -6.166151 -10.106408 -7.469214 -6.524183 -5.088352 -7.761166 -6.413837   \n\n        7          8         9    ...       196        197       198  \\\n0 -8.033804 -10.087412 -5.564300  ... -8.618535 -11.183626 -7.293645   \n1 -6.701095  -7.309774 -4.652847  ... -7.827489 -10.568341 -7.319203   \n2 -9.541793 -11.008221 -6.788436  ... -8.877191 -12.790099 -7.860549   \n3 -8.262154  -9.795920 -6.343618  ... -8.630685 -11.386888 -7.383839   \n4 -9.067953 -10.801625 -6.248049  ... -8.563482 -11.752374 -6.996154   \n\n         199        200        201        202       203       204       205  \n0 -11.804387 -10.625091 -10.114108  -9.568006 -7.016848 -7.428362 -6.802690  \n1 -11.627129  -6.584890  -9.558182  -6.608545 -6.337615 -7.028562 -6.624512  \n2 -11.668090 -10.822981 -11.931119 -10.567121 -7.273679 -8.874907 -7.058156  \n3  -9.601575  -8.113172 -10.837913  -8.301046 -7.040994 -7.388807 -6.306052  \n4 -10.698910 -11.057872 -10.738637 -10.271218 -7.486642 -8.360163 -7.392129  \n\n[5 rows x 206 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>196</th>\n      <th>197</th>\n      <th>198</th>\n      <th>199</th>\n      <th>200</th>\n      <th>201</th>\n      <th>202</th>\n      <th>203</th>\n      <th>204</th>\n      <th>205</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-6.906514</td>\n      <td>-10.037319</td>\n      <td>-7.067277</td>\n      <td>-5.738963</td>\n      <td>-4.801744</td>\n      <td>-7.583585</td>\n      <td>-6.978337</td>\n      <td>-8.033804</td>\n      <td>-10.087412</td>\n      <td>-5.564300</td>\n      <td>...</td>\n      <td>-8.618535</td>\n      <td>-11.183626</td>\n      <td>-7.293645</td>\n      <td>-11.804387</td>\n      <td>-10.625091</td>\n      <td>-10.114108</td>\n      <td>-9.568006</td>\n      <td>-7.016848</td>\n      <td>-7.428362</td>\n      <td>-6.802690</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-7.721139</td>\n      <td>-10.020224</td>\n      <td>-6.574782</td>\n      <td>-6.825776</td>\n      <td>-4.716693</td>\n      <td>-6.878952</td>\n      <td>-6.121612</td>\n      <td>-6.701095</td>\n      <td>-7.309774</td>\n      <td>-4.652847</td>\n      <td>...</td>\n      <td>-7.827489</td>\n      <td>-10.568341</td>\n      <td>-7.319203</td>\n      <td>-11.627129</td>\n      <td>-6.584890</td>\n      <td>-9.558182</td>\n      <td>-6.608545</td>\n      <td>-6.337615</td>\n      <td>-7.028562</td>\n      <td>-6.624512</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-8.474200</td>\n      <td>-12.549698</td>\n      <td>-7.744347</td>\n      <td>-6.534324</td>\n      <td>-5.394559</td>\n      <td>-8.327050</td>\n      <td>-7.023392</td>\n      <td>-9.541793</td>\n      <td>-11.008221</td>\n      <td>-6.788436</td>\n      <td>...</td>\n      <td>-8.877191</td>\n      <td>-12.790099</td>\n      <td>-7.860549</td>\n      <td>-11.668090</td>\n      <td>-10.822981</td>\n      <td>-11.931119</td>\n      <td>-10.567121</td>\n      <td>-7.273679</td>\n      <td>-8.874907</td>\n      <td>-7.058156</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-7.345932</td>\n      <td>-10.993735</td>\n      <td>-7.128180</td>\n      <td>-6.974970</td>\n      <td>-5.456245</td>\n      <td>-7.196219</td>\n      <td>-7.282748</td>\n      <td>-8.262154</td>\n      <td>-9.795920</td>\n      <td>-6.343618</td>\n      <td>...</td>\n      <td>-8.630685</td>\n      <td>-11.386888</td>\n      <td>-7.383839</td>\n      <td>-9.601575</td>\n      <td>-8.113172</td>\n      <td>-10.837913</td>\n      <td>-8.301046</td>\n      <td>-7.040994</td>\n      <td>-7.388807</td>\n      <td>-6.306052</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-6.166151</td>\n      <td>-10.106408</td>\n      <td>-7.469214</td>\n      <td>-6.524183</td>\n      <td>-5.088352</td>\n      <td>-7.761166</td>\n      <td>-6.413837</td>\n      <td>-9.067953</td>\n      <td>-10.801625</td>\n      <td>-6.248049</td>\n      <td>...</td>\n      <td>-8.563482</td>\n      <td>-11.752374</td>\n      <td>-6.996154</td>\n      <td>-10.698910</td>\n      <td>-11.057872</td>\n      <td>-10.738637</td>\n      <td>-10.271218</td>\n      <td>-7.486642</td>\n      <td>-8.360163</td>\n      <td>-7.392129</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 206 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_sub.columns = submission.columns[1:]\nfinal_sub[\"sig_id\"] = submission[\"sig_id\"]\n","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_sub.head()","execution_count":71,"outputs":[{"output_type":"execute_result","execution_count":71,"data":{"text/plain":"   5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n0                    -6.906514              -10.037319       -7.067277   \n1                    -7.721139              -10.020224       -6.574782   \n2                    -8.474200              -12.549698       -7.744347   \n3                    -7.345932              -10.993735       -7.128180   \n4                    -6.166151              -10.106408       -7.469214   \n\n   acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n0                       -5.738963                          -4.801744   \n1                       -6.825776                          -4.716693   \n2                       -6.534324                          -5.394559   \n3                       -6.974970                          -5.456245   \n4                       -6.524183                          -5.088352   \n\n   acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n0                       -7.583585                   -6.978337   \n1                       -6.878952                   -6.121612   \n2                       -8.327050                   -7.023392   \n3                       -7.196219                   -7.282748   \n4                       -7.761166                   -6.413837   \n\n   adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n0                      -8.033804                  -10.087412   \n1                      -6.701095                   -7.309774   \n2                      -9.541793                  -11.008221   \n3                      -8.262154                   -9.795920   \n4                      -9.067953                  -10.801625   \n\n   adrenergic_receptor_agonist  ...  trpv_agonist  trpv_antagonist  \\\n0                    -5.564300  ...    -11.183626        -7.293645   \n1                    -4.652847  ...    -10.568341        -7.319203   \n2                    -6.788436  ...    -12.790099        -7.860549   \n3                    -6.343618  ...    -11.386888        -7.383839   \n4                    -6.248049  ...    -11.752374        -6.996154   \n\n   tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n0         -11.804387                 -10.625091   \n1         -11.627129                  -6.584890   \n2         -11.668090                 -10.822981   \n3          -9.601575                  -8.113172   \n4         -10.698910                 -11.057872   \n\n   ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n0                             -10.114108        -9.568006  -7.016848   \n1                              -9.558182        -6.608545  -6.337615   \n2                             -11.931119       -10.567121  -7.273679   \n3                             -10.837913        -8.301046  -7.040994   \n4                             -10.738637       -10.271218  -7.486642   \n\n   vitamin_d_receptor_agonist  wnt_inhibitor        sig_id  \n0                   -7.428362      -6.802690  id_0004d9e33  \n1                   -7.028562      -6.624512  id_001897cda  \n2                   -8.874907      -7.058156  id_002429b5b  \n3                   -7.388807      -6.306052  id_00276f245  \n4                   -8.360163      -7.392129  id_0027f1083  \n\n[5 rows x 207 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>5-alpha_reductase_inhibitor</th>\n      <th>11-beta-hsd1_inhibitor</th>\n      <th>acat_inhibitor</th>\n      <th>acetylcholine_receptor_agonist</th>\n      <th>acetylcholine_receptor_antagonist</th>\n      <th>acetylcholinesterase_inhibitor</th>\n      <th>adenosine_receptor_agonist</th>\n      <th>adenosine_receptor_antagonist</th>\n      <th>adenylyl_cyclase_activator</th>\n      <th>adrenergic_receptor_agonist</th>\n      <th>...</th>\n      <th>trpv_agonist</th>\n      <th>trpv_antagonist</th>\n      <th>tubulin_inhibitor</th>\n      <th>tyrosine_kinase_inhibitor</th>\n      <th>ubiquitin_specific_protease_inhibitor</th>\n      <th>vegfr_inhibitor</th>\n      <th>vitamin_b</th>\n      <th>vitamin_d_receptor_agonist</th>\n      <th>wnt_inhibitor</th>\n      <th>sig_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-6.906514</td>\n      <td>-10.037319</td>\n      <td>-7.067277</td>\n      <td>-5.738963</td>\n      <td>-4.801744</td>\n      <td>-7.583585</td>\n      <td>-6.978337</td>\n      <td>-8.033804</td>\n      <td>-10.087412</td>\n      <td>-5.564300</td>\n      <td>...</td>\n      <td>-11.183626</td>\n      <td>-7.293645</td>\n      <td>-11.804387</td>\n      <td>-10.625091</td>\n      <td>-10.114108</td>\n      <td>-9.568006</td>\n      <td>-7.016848</td>\n      <td>-7.428362</td>\n      <td>-6.802690</td>\n      <td>id_0004d9e33</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-7.721139</td>\n      <td>-10.020224</td>\n      <td>-6.574782</td>\n      <td>-6.825776</td>\n      <td>-4.716693</td>\n      <td>-6.878952</td>\n      <td>-6.121612</td>\n      <td>-6.701095</td>\n      <td>-7.309774</td>\n      <td>-4.652847</td>\n      <td>...</td>\n      <td>-10.568341</td>\n      <td>-7.319203</td>\n      <td>-11.627129</td>\n      <td>-6.584890</td>\n      <td>-9.558182</td>\n      <td>-6.608545</td>\n      <td>-6.337615</td>\n      <td>-7.028562</td>\n      <td>-6.624512</td>\n      <td>id_001897cda</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-8.474200</td>\n      <td>-12.549698</td>\n      <td>-7.744347</td>\n      <td>-6.534324</td>\n      <td>-5.394559</td>\n      <td>-8.327050</td>\n      <td>-7.023392</td>\n      <td>-9.541793</td>\n      <td>-11.008221</td>\n      <td>-6.788436</td>\n      <td>...</td>\n      <td>-12.790099</td>\n      <td>-7.860549</td>\n      <td>-11.668090</td>\n      <td>-10.822981</td>\n      <td>-11.931119</td>\n      <td>-10.567121</td>\n      <td>-7.273679</td>\n      <td>-8.874907</td>\n      <td>-7.058156</td>\n      <td>id_002429b5b</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-7.345932</td>\n      <td>-10.993735</td>\n      <td>-7.128180</td>\n      <td>-6.974970</td>\n      <td>-5.456245</td>\n      <td>-7.196219</td>\n      <td>-7.282748</td>\n      <td>-8.262154</td>\n      <td>-9.795920</td>\n      <td>-6.343618</td>\n      <td>...</td>\n      <td>-11.386888</td>\n      <td>-7.383839</td>\n      <td>-9.601575</td>\n      <td>-8.113172</td>\n      <td>-10.837913</td>\n      <td>-8.301046</td>\n      <td>-7.040994</td>\n      <td>-7.388807</td>\n      <td>-6.306052</td>\n      <td>id_00276f245</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-6.166151</td>\n      <td>-10.106408</td>\n      <td>-7.469214</td>\n      <td>-6.524183</td>\n      <td>-5.088352</td>\n      <td>-7.761166</td>\n      <td>-6.413837</td>\n      <td>-9.067953</td>\n      <td>-10.801625</td>\n      <td>-6.248049</td>\n      <td>...</td>\n      <td>-11.752374</td>\n      <td>-6.996154</td>\n      <td>-10.698910</td>\n      <td>-11.057872</td>\n      <td>-10.738637</td>\n      <td>-10.271218</td>\n      <td>-7.486642</td>\n      <td>-8.360163</td>\n      <td>-7.392129</td>\n      <td>id_0027f1083</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 207 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"good_cols = np.roll(final_sub.columns.values, 1)\nfinal_sub = final_sub[good_cols]","execution_count":72,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scale_bw_0_1(df, immune_col):\n    dummy_df = df.loc[:, df.columns != immune_col]\n    df_float = dummy_df.astype(float)\n    scaler = MinMaxScaler()\n    df_float_scaled = pd.DataFrame(scaler.fit_transform(df_float), columns = df_float.columns)\n    df_float_scaled[immune_col] = df[immune_col]\n    \n    good_cols = np.roll(df_float_scaled.columns.values, 1)\n    final_sub = df_float_scaled[good_cols]\n    \n    return(final_sub)\n\nscaled_sub = scale_bw_0_1(final_sub, 'sig_id')","execution_count":73,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_sub.to_csv(\"./submission.csv\", index=False)\nfinal_sub","execution_count":74,"outputs":[{"output_type":"execute_result","execution_count":74,"data":{"text/plain":"            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n0     id_0004d9e33                    -6.906514              -10.037319   \n1     id_001897cda                    -7.721139              -10.020224   \n2     id_002429b5b                    -8.474200              -12.549698   \n3     id_00276f245                    -7.345932              -10.993735   \n4     id_0027f1083                    -6.166151              -10.106408   \n...            ...                          ...                     ...   \n3977  id_ff7004b87                    -5.897729               -8.385771   \n3978  id_ff925dd0d                    -5.849936               -9.878220   \n3979  id_ffb710450                    -6.224284              -10.551744   \n3980  id_ffbb869f2                    -7.269462              -11.105717   \n3981  id_ffd5800b6                    -7.235862               -9.879771   \n\n      acat_inhibitor  acetylcholine_receptor_agonist  \\\n0          -7.067277                       -5.738963   \n1          -6.574782                       -6.825776   \n2          -7.744347                       -6.534324   \n3          -7.128180                       -6.974970   \n4          -7.469214                       -6.524183   \n...              ...                             ...   \n3977       -6.747713                       -6.251032   \n3978       -7.683170                       -6.599363   \n3979       -8.068488                       -6.824511   \n3980       -7.729827                       -6.069247   \n3981       -7.106522                       -5.791350   \n\n      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n0                             -4.801744                       -7.583585   \n1                             -4.716693                       -6.878952   \n2                             -5.394559                       -8.327050   \n3                             -5.456245                       -7.196219   \n4                             -5.088352                       -7.761166   \n...                                 ...                             ...   \n3977                          -4.392544                       -6.843883   \n3978                          -4.763426                       -8.134160   \n3979                          -4.265887                       -7.380076   \n3980                          -5.048457                       -7.715062   \n3981                          -4.380522                       -8.128676   \n\n      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n0                      -6.978337                      -8.033804   \n1                      -6.121612                      -6.701095   \n2                      -7.023392                      -9.541793   \n3                      -7.282748                      -8.262154   \n4                      -6.413837                      -9.067953   \n...                          ...                            ...   \n3977                   -6.524404                      -6.725145   \n3978                   -6.242714                      -8.939557   \n3979                   -6.474818                      -8.895263   \n3980                   -7.204977                      -9.066048   \n3981                   -6.074333                      -7.551010   \n\n      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n0                     -10.087412  ...                              -8.618535   \n1                      -7.309774  ...                              -7.827489   \n2                     -11.008221  ...                              -8.877191   \n3                      -9.795920  ...                              -8.630685   \n4                     -10.801625  ...                              -8.563482   \n...                          ...  ...                                    ...   \n3977                   -8.192734  ...                              -7.818218   \n3978                  -10.611772  ...                              -9.181347   \n3979                  -10.927665  ...                              -9.211755   \n3980                  -11.195934  ...                             -10.355356   \n3981                  -10.065438  ...                              -8.271853   \n\n      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n0       -11.183626        -7.293645         -11.804387   \n1       -10.568341        -7.319203         -11.627129   \n2       -12.790099        -7.860549         -11.668090   \n3       -11.386888        -7.383839          -9.601575   \n4       -11.752374        -6.996154         -10.698910   \n...            ...              ...                ...   \n3977     -9.833197        -6.372848          -8.910477   \n3978    -12.437528        -7.295601         -12.006838   \n3979    -12.886572        -8.232035         -12.193651   \n3980    -13.499394        -7.617971         -12.391840   \n3981    -10.701745        -7.127091         -11.325402   \n\n      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n0                    -10.625091                             -10.114108   \n1                     -6.584890                              -9.558182   \n2                    -10.822981                             -11.931119   \n3                     -8.113172                             -10.837913   \n4                    -11.057872                             -10.738637   \n...                         ...                                    ...   \n3977                  -6.743455                              -9.007614   \n3978                 -11.408297                             -10.790997   \n3979                 -10.788119                             -11.253053   \n3980                 -10.958365                             -11.487015   \n3981                  -9.639734                             -10.077198   \n\n      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n0           -9.568006  -7.016848                   -7.428362      -6.802690  \n1           -6.608545  -6.337615                   -7.028562      -6.624512  \n2          -10.567121  -7.273679                   -8.874907      -7.058156  \n3           -8.301046  -7.040994                   -7.388807      -6.306052  \n4          -10.271218  -7.486642                   -8.360163      -7.392129  \n...               ...        ...                         ...            ...  \n3977        -6.869778  -6.520425                   -6.830815      -6.672807  \n3978        -9.812609  -7.261048                   -8.932777      -7.622788  \n3979       -11.619781  -7.776727                   -9.224164      -7.647622  \n3980        -9.863905  -8.523955                   -7.938643      -6.804509  \n3981        -8.786296  -6.424324                   -8.348071      -7.496436  \n\n[3982 rows x 207 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sig_id</th>\n      <th>5-alpha_reductase_inhibitor</th>\n      <th>11-beta-hsd1_inhibitor</th>\n      <th>acat_inhibitor</th>\n      <th>acetylcholine_receptor_agonist</th>\n      <th>acetylcholine_receptor_antagonist</th>\n      <th>acetylcholinesterase_inhibitor</th>\n      <th>adenosine_receptor_agonist</th>\n      <th>adenosine_receptor_antagonist</th>\n      <th>adenylyl_cyclase_activator</th>\n      <th>...</th>\n      <th>tropomyosin_receptor_kinase_inhibitor</th>\n      <th>trpv_agonist</th>\n      <th>trpv_antagonist</th>\n      <th>tubulin_inhibitor</th>\n      <th>tyrosine_kinase_inhibitor</th>\n      <th>ubiquitin_specific_protease_inhibitor</th>\n      <th>vegfr_inhibitor</th>\n      <th>vitamin_b</th>\n      <th>vitamin_d_receptor_agonist</th>\n      <th>wnt_inhibitor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_0004d9e33</td>\n      <td>-6.906514</td>\n      <td>-10.037319</td>\n      <td>-7.067277</td>\n      <td>-5.738963</td>\n      <td>-4.801744</td>\n      <td>-7.583585</td>\n      <td>-6.978337</td>\n      <td>-8.033804</td>\n      <td>-10.087412</td>\n      <td>...</td>\n      <td>-8.618535</td>\n      <td>-11.183626</td>\n      <td>-7.293645</td>\n      <td>-11.804387</td>\n      <td>-10.625091</td>\n      <td>-10.114108</td>\n      <td>-9.568006</td>\n      <td>-7.016848</td>\n      <td>-7.428362</td>\n      <td>-6.802690</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_001897cda</td>\n      <td>-7.721139</td>\n      <td>-10.020224</td>\n      <td>-6.574782</td>\n      <td>-6.825776</td>\n      <td>-4.716693</td>\n      <td>-6.878952</td>\n      <td>-6.121612</td>\n      <td>-6.701095</td>\n      <td>-7.309774</td>\n      <td>...</td>\n      <td>-7.827489</td>\n      <td>-10.568341</td>\n      <td>-7.319203</td>\n      <td>-11.627129</td>\n      <td>-6.584890</td>\n      <td>-9.558182</td>\n      <td>-6.608545</td>\n      <td>-6.337615</td>\n      <td>-7.028562</td>\n      <td>-6.624512</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_002429b5b</td>\n      <td>-8.474200</td>\n      <td>-12.549698</td>\n      <td>-7.744347</td>\n      <td>-6.534324</td>\n      <td>-5.394559</td>\n      <td>-8.327050</td>\n      <td>-7.023392</td>\n      <td>-9.541793</td>\n      <td>-11.008221</td>\n      <td>...</td>\n      <td>-8.877191</td>\n      <td>-12.790099</td>\n      <td>-7.860549</td>\n      <td>-11.668090</td>\n      <td>-10.822981</td>\n      <td>-11.931119</td>\n      <td>-10.567121</td>\n      <td>-7.273679</td>\n      <td>-8.874907</td>\n      <td>-7.058156</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_00276f245</td>\n      <td>-7.345932</td>\n      <td>-10.993735</td>\n      <td>-7.128180</td>\n      <td>-6.974970</td>\n      <td>-5.456245</td>\n      <td>-7.196219</td>\n      <td>-7.282748</td>\n      <td>-8.262154</td>\n      <td>-9.795920</td>\n      <td>...</td>\n      <td>-8.630685</td>\n      <td>-11.386888</td>\n      <td>-7.383839</td>\n      <td>-9.601575</td>\n      <td>-8.113172</td>\n      <td>-10.837913</td>\n      <td>-8.301046</td>\n      <td>-7.040994</td>\n      <td>-7.388807</td>\n      <td>-6.306052</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_0027f1083</td>\n      <td>-6.166151</td>\n      <td>-10.106408</td>\n      <td>-7.469214</td>\n      <td>-6.524183</td>\n      <td>-5.088352</td>\n      <td>-7.761166</td>\n      <td>-6.413837</td>\n      <td>-9.067953</td>\n      <td>-10.801625</td>\n      <td>...</td>\n      <td>-8.563482</td>\n      <td>-11.752374</td>\n      <td>-6.996154</td>\n      <td>-10.698910</td>\n      <td>-11.057872</td>\n      <td>-10.738637</td>\n      <td>-10.271218</td>\n      <td>-7.486642</td>\n      <td>-8.360163</td>\n      <td>-7.392129</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3977</th>\n      <td>id_ff7004b87</td>\n      <td>-5.897729</td>\n      <td>-8.385771</td>\n      <td>-6.747713</td>\n      <td>-6.251032</td>\n      <td>-4.392544</td>\n      <td>-6.843883</td>\n      <td>-6.524404</td>\n      <td>-6.725145</td>\n      <td>-8.192734</td>\n      <td>...</td>\n      <td>-7.818218</td>\n      <td>-9.833197</td>\n      <td>-6.372848</td>\n      <td>-8.910477</td>\n      <td>-6.743455</td>\n      <td>-9.007614</td>\n      <td>-6.869778</td>\n      <td>-6.520425</td>\n      <td>-6.830815</td>\n      <td>-6.672807</td>\n    </tr>\n    <tr>\n      <th>3978</th>\n      <td>id_ff925dd0d</td>\n      <td>-5.849936</td>\n      <td>-9.878220</td>\n      <td>-7.683170</td>\n      <td>-6.599363</td>\n      <td>-4.763426</td>\n      <td>-8.134160</td>\n      <td>-6.242714</td>\n      <td>-8.939557</td>\n      <td>-10.611772</td>\n      <td>...</td>\n      <td>-9.181347</td>\n      <td>-12.437528</td>\n      <td>-7.295601</td>\n      <td>-12.006838</td>\n      <td>-11.408297</td>\n      <td>-10.790997</td>\n      <td>-9.812609</td>\n      <td>-7.261048</td>\n      <td>-8.932777</td>\n      <td>-7.622788</td>\n    </tr>\n    <tr>\n      <th>3979</th>\n      <td>id_ffb710450</td>\n      <td>-6.224284</td>\n      <td>-10.551744</td>\n      <td>-8.068488</td>\n      <td>-6.824511</td>\n      <td>-4.265887</td>\n      <td>-7.380076</td>\n      <td>-6.474818</td>\n      <td>-8.895263</td>\n      <td>-10.927665</td>\n      <td>...</td>\n      <td>-9.211755</td>\n      <td>-12.886572</td>\n      <td>-8.232035</td>\n      <td>-12.193651</td>\n      <td>-10.788119</td>\n      <td>-11.253053</td>\n      <td>-11.619781</td>\n      <td>-7.776727</td>\n      <td>-9.224164</td>\n      <td>-7.647622</td>\n    </tr>\n    <tr>\n      <th>3980</th>\n      <td>id_ffbb869f2</td>\n      <td>-7.269462</td>\n      <td>-11.105717</td>\n      <td>-7.729827</td>\n      <td>-6.069247</td>\n      <td>-5.048457</td>\n      <td>-7.715062</td>\n      <td>-7.204977</td>\n      <td>-9.066048</td>\n      <td>-11.195934</td>\n      <td>...</td>\n      <td>-10.355356</td>\n      <td>-13.499394</td>\n      <td>-7.617971</td>\n      <td>-12.391840</td>\n      <td>-10.958365</td>\n      <td>-11.487015</td>\n      <td>-9.863905</td>\n      <td>-8.523955</td>\n      <td>-7.938643</td>\n      <td>-6.804509</td>\n    </tr>\n    <tr>\n      <th>3981</th>\n      <td>id_ffd5800b6</td>\n      <td>-7.235862</td>\n      <td>-9.879771</td>\n      <td>-7.106522</td>\n      <td>-5.791350</td>\n      <td>-4.380522</td>\n      <td>-8.128676</td>\n      <td>-6.074333</td>\n      <td>-7.551010</td>\n      <td>-10.065438</td>\n      <td>...</td>\n      <td>-8.271853</td>\n      <td>-10.701745</td>\n      <td>-7.127091</td>\n      <td>-11.325402</td>\n      <td>-9.639734</td>\n      <td>-10.077198</td>\n      <td>-8.786296</td>\n      <td>-6.424324</td>\n      <td>-8.348071</td>\n      <td>-7.496436</td>\n    </tr>\n  </tbody>\n</table>\n<p>3982 rows × 207 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}